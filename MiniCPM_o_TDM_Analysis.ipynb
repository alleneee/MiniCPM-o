{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MiniCPM-o æ—¶åˆ†å¤ç”¨ï¼ˆTDMï¼‰æœºåˆ¶æ·±åº¦åˆ†æ\n",
    "\n",
    "## æ¦‚è¿°\n",
    "\n",
    "æœ¬Notebookæ·±å…¥åˆ†æMiniCPM-oä¸­æ—¶åˆ†å¤ç”¨ï¼ˆTime Division Multiplexing, TDMï¼‰æœºåˆ¶çš„åŸç†ã€å®ç°å’Œåº”ç”¨ã€‚TDMæ˜¯MiniCPM-oå®ç°çœŸæ­£å®æ—¶å¤šæ¨¡æ€äº¤äº’çš„æ ¸å¿ƒæŠ€æœ¯ï¼Œå®ƒè§£å†³äº†éŸ³é¢‘ã€è§†é¢‘ã€æ–‡æœ¬ç­‰ä¸åŒæ¨¡æ€æ•°æ®çš„æ—¶åºåŒæ­¥é—®é¢˜ã€‚\n",
    "\n",
    "### ä¸»è¦å†…å®¹\n",
    "1. **ç†è®ºåŸºç¡€**ï¼šTDMåœ¨å¤šæ¨¡æ€AIä¸­çš„æ¦‚å¿µå’Œä½œç”¨\n",
    "2. **æŠ€æœ¯åŸç†**ï¼šæ—¶é—´ç‰‡åˆ†é…ã€æ—¶åºå¯¹é½ã€ç¼“å†²åŒºç®¡ç†\n",
    "3. **æºç å®ç°**ï¼šå®Œæ•´çš„Pythonå®ç°å’Œæ ¸å¿ƒç®—æ³•\n",
    "4. **åº”ç”¨ç¤ºä¾‹**ï¼šå®æ—¶å¤šæ¨¡æ€å¯¹è¯åœºæ™¯æ¼”ç¤º\n",
    "5. **æŠ€æœ¯ç»†èŠ‚**ï¼šæ€§èƒ½ä¼˜åŒ–ã€å¹¶å‘å¤„ç†ã€é”™è¯¯å¤„ç†\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç†è®ºåŸºç¡€\n",
    "\n",
    "### 1.1 æ—¶åˆ†å¤ç”¨åœ¨å¤šæ¨¡æ€AIä¸­çš„æ¦‚å¿µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import threading\n",
    "import queue\n",
    "import time\n",
    "from typing import Dict, List, Optional, Tuple, Any\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "import logging\n",
    "\n",
    "# é…ç½®æ—¥å¿—\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class ModalityType(Enum):\n",
    "    \"\"\"\n",
    "    æ¨¡æ€ç±»å‹æšä¸¾\n",
    "    å®šä¹‰MiniCPM-oæ”¯æŒçš„ä¸åŒè¾“å…¥æ¨¡æ€\n",
    "    \"\"\"\n",
    "    TEXT = \"text\"           # æ–‡æœ¬æ¨¡æ€\n",
    "    AUDIO = \"audio\"         # éŸ³é¢‘æ¨¡æ€\n",
    "    VIDEO = \"video\"         # è§†é¢‘æ¨¡æ€\n",
    "    IMAGE = \"image\"         # å›¾åƒæ¨¡æ€\n",
    "\n",
    "@dataclass\n",
    "class ModalityData:\n",
    "    \"\"\"\n",
    "    æ¨¡æ€æ•°æ®ç»“æ„\n",
    "    å°è£…ä¸åŒæ¨¡æ€çš„æ•°æ®å’Œå…ƒä¿¡æ¯\n",
    "    \"\"\"\n",
    "    modality_type: ModalityType  # æ¨¡æ€ç±»å‹\n",
    "    data: Any                    # å®é™…æ•°æ®\n",
    "    timestamp: float             # æ—¶é—´æˆ³ï¼ˆç§’ï¼‰\n",
    "    duration: float              # æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰\n",
    "    sequence_id: int             # åºåˆ—ID\n",
    "    metadata: Dict[str, Any]     # å…ƒæ•°æ®\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        \"\"\"æ•°æ®éªŒè¯å’Œé¢„å¤„ç†\"\"\"\n",
    "        if self.timestamp < 0:\n",
    "            raise ValueError(\"æ—¶é—´æˆ³ä¸èƒ½ä¸ºè´Ÿæ•°\")\n",
    "        if self.duration <= 0:\n",
    "            raise ValueError(\"æŒç»­æ—¶é—´å¿…é¡»ä¸ºæ­£æ•°\")\n",
    "\n",
    "print(\"âœ… åŸºç¡€æ•°æ®ç»“æ„å®šä¹‰å®Œæˆ\")\n",
    "print(\"æ”¯æŒçš„æ¨¡æ€ç±»å‹:\", [m.value for m in ModalityType])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 TDMçš„æ ¸å¿ƒæ¦‚å¿µå’Œä¼˜åŠ¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TDMConceptAnalysis:\n",
    "    \"\"\"\n",
    "    TDMæ¦‚å¿µåˆ†æç±»\n",
    "    è§£é‡Šæ—¶åˆ†å¤ç”¨åœ¨å¤šæ¨¡æ€AIä¸­çš„æ ¸å¿ƒæ¦‚å¿µå’Œä¼˜åŠ¿\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.concept_explanation = {\n",
    "            \"åŸºæœ¬æ¦‚å¿µ\": {\n",
    "                \"å®šä¹‰\": \"æ—¶åˆ†å¤ç”¨æ˜¯ä¸€ç§å°†ä¸åŒæ¨¡æ€çš„æ•°æ®æŒ‰æ—¶é—´ç‰‡è½®æµå¤„ç†çš„æŠ€æœ¯\",\n",
    "                \"æ ¸å¿ƒæ€æƒ³\": \"åœ¨æ—¶é—´ç»´åº¦ä¸Šåè°ƒå¤šä¸ªæ¨¡æ€çš„æ•°æ®æµï¼Œç¡®ä¿æ—¶åºä¸€è‡´æ€§\",\n",
    "                \"åº”ç”¨åœºæ™¯\": \"å®æ—¶å¤šæ¨¡æ€å¯¹è¯ã€è§†é¢‘ç†è§£ã€éŸ³è§†é¢‘åŒæ­¥ç­‰\"\n",
    "            },\n",
    "            \"æŠ€æœ¯ä¼˜åŠ¿\": {\n",
    "                \"æ—¶åºåŒæ­¥\": \"ç¡®ä¿ä¸åŒæ¨¡æ€æ•°æ®åœ¨æ—¶é—´è½´ä¸Šçš„ç²¾ç¡®å¯¹é½\",\n",
    "                \"èµ„æºä¼˜åŒ–\": \"é¿å…åŒæ—¶å¤„ç†å¤šä¸ªæ¨¡æ€é€ æˆçš„èµ„æºç«äº‰\",\n",
    "                \"å®æ—¶æ€§ä¿è¯\": \"é€šè¿‡æ—¶é—´ç‰‡è°ƒåº¦ä¿è¯ç³»ç»Ÿå“åº”çš„å®æ—¶æ€§\",\n",
    "                \"å¯æ‰©å±•æ€§\": \"æ˜“äºæ·»åŠ æ–°çš„æ¨¡æ€ç±»å‹è€Œä¸å½±å“ç°æœ‰ç³»ç»Ÿ\"\n",
    "            },\n",
    "            \"ä¸ä¼ ç»Ÿæ–¹æ³•å¯¹æ¯”\": {\n",
    "                \"ä¼ ç»Ÿç‰¹å¾èåˆ\": {\n",
    "                    \"æ–¹æ³•\": \"å°†æ‰€æœ‰æ¨¡æ€ç‰¹å¾æ‹¼æ¥æˆ–åŠ æƒèåˆ\",\n",
    "                    \"ä¼˜ç‚¹\": \"å®ç°ç®€å•ï¼Œè®¡ç®—ç›´è§‚\",\n",
    "                    \"ç¼ºç‚¹\": \"å¿½ç•¥æ—¶åºä¿¡æ¯ï¼Œæ— æ³•å¤„ç†å®æ—¶æ•°æ®æµ\"\n",
    "                },\n",
    "                \"TDMæ–¹æ³•\": {\n",
    "                    \"æ–¹æ³•\": \"æŒ‰æ—¶é—´ç‰‡è½®æµå¤„ç†ä¸åŒæ¨¡æ€ï¼Œä¿æŒæ—¶åºå…³ç³»\",\n",
    "                    \"ä¼˜ç‚¹\": \"æ—¶åºç²¾ç¡®ï¼Œæ”¯æŒå®æ—¶å¤„ç†ï¼Œèµ„æºåˆ©ç”¨é«˜æ•ˆ\",\n",
    "                    \"ç¼ºç‚¹\": \"å®ç°å¤æ‚ï¼Œéœ€è¦ç²¾ç¡®çš„æ—¶é—´æ§åˆ¶\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "    def explain_concepts(self):\n",
    "        \"\"\"\n",
    "        è§£é‡ŠTDMçš„æ ¸å¿ƒæ¦‚å¿µ\n",
    "        \"\"\"\n",
    "        print(\"ğŸ§  TDMæ ¸å¿ƒæ¦‚å¿µè§£æ\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        for category, details in self.concept_explanation.items():\n",
    "            print(f\"\\nğŸ“š {category}:\")\n",
    "            \n",
    "            if category == \"ä¸ä¼ ç»Ÿæ–¹æ³•å¯¹æ¯”\":\n",
    "                for method, analysis in details.items():\n",
    "                    print(f\"\\n  ğŸ” {method}:\")\n",
    "                    for aspect, description in analysis.items():\n",
    "                        print(f\"    â€¢ {aspect}: {description}\")\n",
    "            else:\n",
    "                for key, value in details.items():\n",
    "                    print(f\"  â€¢ {key}: {value}\")\n",
    "                    \n",
    "    def visualize_tdm_concept(self):\n",
    "        \"\"\"\n",
    "        å¯è§†åŒ–TDMæ¦‚å¿µ\n",
    "        \"\"\"\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
    "        \n",
    "        # ä¼ ç»Ÿæ–¹æ³•ï¼šæ‰€æœ‰æ¨¡æ€åŒæ—¶å¤„ç†\n",
    "        time_points = np.arange(0, 10, 0.1)\n",
    "        ax1.barh(0, 10, height=0.3, color='red', alpha=0.7, label='éŸ³é¢‘å¤„ç†')\n",
    "        ax1.barh(1, 10, height=0.3, color='green', alpha=0.7, label='è§†é¢‘å¤„ç†')\n",
    "        ax1.barh(2, 10, height=0.3, color='blue', alpha=0.7, label='æ–‡æœ¬å¤„ç†')\n",
    "        ax1.set_xlim(0, 10)\n",
    "        ax1.set_ylim(-0.5, 2.5)\n",
    "        ax1.set_xlabel('æ—¶é—´ (ç§’)')\n",
    "        ax1.set_title('ä¼ ç»Ÿæ–¹æ³•ï¼šå¹¶è¡Œå¤„ç†æ‰€æœ‰æ¨¡æ€')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # TDMæ–¹æ³•ï¼šæ—¶é—´ç‰‡è½®è½¬\n",
    "        colors = ['red', 'green', 'blue']\n",
    "        labels = ['éŸ³é¢‘', 'è§†é¢‘', 'æ–‡æœ¬']\n",
    "        \n",
    "        for i in range(30):  # 30ä¸ªæ—¶é—´ç‰‡\n",
    "            modality = i % 3\n",
    "            start_time = i * 0.33\n",
    "            ax2.barh(0, 0.33, left=start_time, height=0.8, \n",
    "                    color=colors[modality], alpha=0.7)\n",
    "            \n",
    "        ax2.set_xlim(0, 10)\n",
    "        ax2.set_ylim(-0.5, 0.5)\n",
    "        ax2.set_xlabel('æ—¶é—´ (ç§’)')\n",
    "        ax2.set_title('TDMæ–¹æ³•ï¼šæ—¶é—´ç‰‡è½®è½¬å¤„ç†')\n",
    "        \n",
    "        # æ·»åŠ å›¾ä¾‹\n",
    "        from matplotlib.patches import Patch\n",
    "        legend_elements = [Patch(facecolor=colors[i], alpha=0.7, label=labels[i]) \n",
    "                          for i in range(3)]\n",
    "        ax2.legend(handles=legend_elements)\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# æ‰§è¡Œæ¦‚å¿µåˆ†æ\n",
    "concept_analyzer = TDMConceptAnalysis()\n",
    "concept_analyzer.explain_concepts()\n",
    "concept_analyzer.visualize_tdm_concept()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. æŠ€æœ¯åŸç†è¯¦è§£\n",
    "\n",
    "### 2.1 æ—¶é—´ç‰‡åˆ†é…ç®—æ³•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSliceScheduler:\n",
    "    \"\"\"\n",
    "    æ—¶é—´ç‰‡è°ƒåº¦å™¨\n",
    "    è´Ÿè´£ä¸ºä¸åŒæ¨¡æ€åˆ†é…å¤„ç†æ—¶é—´ç‰‡\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, slice_duration: float = 0.1):\n",
    "        \"\"\"\n",
    "        åˆå§‹åŒ–æ—¶é—´ç‰‡è°ƒåº¦å™¨\n",
    "        \n",
    "        Args:\n",
    "            slice_duration: æ¯ä¸ªæ—¶é—´ç‰‡çš„æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰\n",
    "        \"\"\"\n",
    "        self.slice_duration = slice_duration\n",
    "        self.current_time = 0.0\n",
    "        self.modality_priorities = {\n",
    "            ModalityType.AUDIO: 3,    # éŸ³é¢‘ä¼˜å…ˆçº§æœ€é«˜ï¼ˆå®æ—¶æ€§è¦æ±‚é«˜ï¼‰\n",
    "            ModalityType.TEXT: 2,     # æ–‡æœ¬ä¼˜å…ˆçº§ä¸­ç­‰\n",
    "            ModalityType.VIDEO: 1,    # è§†é¢‘ä¼˜å…ˆçº§è¾ƒä½ï¼ˆå¯ä»¥å®¹å¿ä¸€å®šå»¶è¿Ÿï¼‰\n",
    "            ModalityType.IMAGE: 1     # å›¾åƒä¼˜å…ˆçº§è¾ƒä½\n",
    "        }\n",
    "        self.modality_quotas = {\n",
    "            ModalityType.AUDIO: 0.4,  # éŸ³é¢‘å ç”¨40%æ—¶é—´ç‰‡\n",
    "            ModalityType.TEXT: 0.3,   # æ–‡æœ¬å ç”¨30%æ—¶é—´ç‰‡\n",
    "            ModalityType.VIDEO: 0.2,  # è§†é¢‘å ç”¨20%æ—¶é—´ç‰‡\n",
    "            ModalityType.IMAGE: 0.1   # å›¾åƒå ç”¨10%æ—¶é—´ç‰‡\n",
    "        }\n",
    "        self.usage_stats = {modality: 0.0 for modality in ModalityType}\n",
    "        \n",
    "    def calculate_next_modality(self, pending_data: Dict[ModalityType, List[ModalityData]]) -> Optional[ModalityType]:\n",
    "        \"\"\"\n",
    "        è®¡ç®—ä¸‹ä¸€ä¸ªåº”è¯¥å¤„ç†çš„æ¨¡æ€\n",
    "        \n",
    "        Args:\n",
    "            pending_data: å¾…å¤„ç†çš„æ•°æ®ï¼ŒæŒ‰æ¨¡æ€ç±»å‹åˆ†ç»„\n",
    "            \n",
    "        Returns:\n",
    "            ä¸‹ä¸€ä¸ªåº”è¯¥å¤„ç†çš„æ¨¡æ€ç±»å‹\n",
    "        \"\"\"\n",
    "        if not pending_data:\n",
    "            return None\n",
    "            \n",
    "        # è¿‡æ»¤å‡ºæœ‰å¾…å¤„ç†æ•°æ®çš„æ¨¡æ€\n",
    "        available_modalities = [modality for modality, data_list in pending_data.items() \n",
    "                               if data_list]\n",
    "        \n",
    "        if not available_modalities:\n",
    "            return None\n",
    "            \n",
    "        # è®¡ç®—æ¯ä¸ªæ¨¡æ€çš„è°ƒåº¦åˆ†æ•°\n",
    "        scores = {}\n",
    "        for modality in available_modalities:\n",
    "            # åŸºç¡€ä¼˜å…ˆçº§åˆ†æ•°\n",
    "            priority_score = self.modality_priorities[modality]\n",
    "            \n",
    "            # é…é¢ä½¿ç”¨æƒ…å†µï¼ˆä½¿ç”¨è¶Šå°‘ï¼Œåˆ†æ•°è¶Šé«˜ï¼‰\n",
    "            quota_score = max(0, self.modality_quotas[modality] - self.usage_stats[modality])\n",
    "            \n",
    "            # æ•°æ®ç´§æ€¥ç¨‹åº¦ï¼ˆç­‰å¾…æ—¶é—´è¶Šé•¿ï¼Œåˆ†æ•°è¶Šé«˜ï¼‰\n",
    "            oldest_data = min(pending_data[modality], key=lambda x: x.timestamp)\n",
    "            urgency_score = self.current_time - oldest_data.timestamp\n",
    "            \n",
    "            # ç»¼åˆåˆ†æ•°\n",
    "            scores[modality] = priority_score * 2 + quota_score * 3 + urgency_score * 1\n",
    "            \n",
    "        # é€‰æ‹©åˆ†æ•°æœ€é«˜çš„æ¨¡æ€\n",
    "        selected_modality = max(scores.keys(), key=lambda x: scores[x])\n",
    "        \n",
    "        # æ›´æ–°ä½¿ç”¨ç»Ÿè®¡\n",
    "        self.usage_stats[selected_modality] += self.slice_duration\n",
    "        \n",
    "        logger.info(f\"é€‰æ‹©æ¨¡æ€: {selected_modality.value}, åˆ†æ•°: {scores[selected_modality]:.3f}\")\n",
    "        \n",
    "        return selected_modality\n",
    "    \n",
    "    def advance_time(self):\n",
    "        \"\"\"\n",
    "        æ¨è¿›æ—¶é—´åˆ°ä¸‹ä¸€ä¸ªæ—¶é—´ç‰‡\n",
    "        \"\"\"\n",
    "        self.current_time += self.slice_duration\n",
    "        \n",
    "        # å®šæœŸé‡ç½®ä½¿ç”¨ç»Ÿè®¡ï¼ˆæ¯ç§’é‡ç½®ä¸€æ¬¡ï¼‰\n",
    "        if self.current_time % 1.0 < self.slice_duration:\n",
    "            self.usage_stats = {modality: 0.0 for modality in ModalityType}\n",
    "            logger.info(\"é‡ç½®æ¨¡æ€ä½¿ç”¨ç»Ÿè®¡\")\n",
    "    \n",
    "    def get_scheduler_status(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        è·å–è°ƒåº¦å™¨çŠ¶æ€ä¿¡æ¯\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"current_time\": self.current_time,\n",
    "            \"slice_duration\": self.slice_duration,\n",
    "            \"usage_stats\": dict(self.usage_stats),\n",
    "            \"modality_quotas\": dict(self.modality_quotas)\n",
    "        }\n",
    "\n",
    "print(\"âœ… æ—¶é—´ç‰‡è°ƒåº¦å™¨å®ç°å®Œæˆ\")\n",
    "print(\"æ”¯æŒä¼˜å…ˆçº§è°ƒåº¦ã€é…é¢ç®¡ç†å’Œç´§æ€¥ç¨‹åº¦è¯„ä¼°\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 æ—¶åºå¯¹é½ç®—æ³•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalAlignmentEngine:\n",
    "    \"\"\"\n",
    "    æ—¶åºå¯¹é½å¼•æ“\n",
    "    è´Ÿè´£å°†ä¸åŒæ¨¡æ€çš„æ•°æ®åœ¨æ—¶é—´è½´ä¸Šç²¾ç¡®å¯¹é½\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, alignment_tolerance: float = 0.05):\n",
    "        \"\"\"\n",
    "        åˆå§‹åŒ–æ—¶åºå¯¹é½å¼•æ“\n",
    "        \n",
    "        Args:\n",
    "            alignment_tolerance: å¯¹é½å®¹å·®ï¼ˆç§’ï¼‰ï¼Œåœ¨æ­¤èŒƒå›´å†…çš„æ•°æ®è¢«è®¤ä¸ºæ˜¯åŒæ­¥çš„\n",
    "        \"\"\"\n",
    "        self.alignment_tolerance = alignment_tolerance\n",
    "        self.reference_timeline = []  # å‚è€ƒæ—¶é—´çº¿\n",
    "        self.aligned_groups = []      # å¯¹é½åçš„æ•°æ®ç»„\n",
    "        \n",
    "    def create_reference_timeline(self, all_data: List[ModalityData]) -> List[float]:\n",
    "        \"\"\"\n",
    "        åˆ›å»ºå‚è€ƒæ—¶é—´çº¿\n",
    "        \n",
    "        Args:\n",
    "            all_data: æ‰€æœ‰æ¨¡æ€çš„æ•°æ®\n",
    "            \n",
    "        Returns:\n",
    "            å‚è€ƒæ—¶é—´ç‚¹åˆ—è¡¨\n",
    "        \"\"\"\n",
    "        # æ”¶é›†æ‰€æœ‰æ—¶é—´æˆ³\n",
    "        timestamps = [data.timestamp for data in all_data]\n",
    "        \n",
    "        if not timestamps:\n",
    "            return []\n",
    "            \n",
    "        # åˆ›å»ºå‡åŒ€åˆ†å¸ƒçš„æ—¶é—´ç½‘æ ¼\n",
    "        min_time = min(timestamps)\n",
    "        max_time = max(timestamps)\n",
    "        \n",
    "        # ä½¿ç”¨æœ€å°å¯¹é½å®¹å·®ä½œä¸ºæ—¶é—´ç½‘æ ¼é—´éš”\n",
    "        time_step = self.alignment_tolerance / 2\n",
    "        \n",
    "        self.reference_timeline = np.arange(min_time, max_time + time_step, time_step).tolist()\n",
    "        \n",
    "        logger.info(f\"åˆ›å»ºå‚è€ƒæ—¶é—´çº¿: {len(self.reference_timeline)} ä¸ªæ—¶é—´ç‚¹\")\n",
    "        logger.info(f\"æ—¶é—´èŒƒå›´: {min_time:.3f}s - {max_time:.3f}s\")\n",
    "        \n",
    "        return self.reference_timeline\n",
    "    \n",
    "    def align_modality_data(self, data_by_modality: Dict[ModalityType, List[ModalityData]]) -> List[Dict[ModalityType, ModalityData]]:\n",
    "        \"\"\"\n",
    "        å¯¹é½ä¸åŒæ¨¡æ€çš„æ•°æ®\n",
    "        \n",
    "        Args:\n",
    "            data_by_modality: æŒ‰æ¨¡æ€åˆ†ç»„çš„æ•°æ®\n",
    "            \n",
    "        Returns:\n",
    "            å¯¹é½åçš„æ•°æ®ç»„åˆ—è¡¨ï¼Œæ¯ç»„åŒ…å«åŒä¸€æ—¶é—´ç‚¹çš„ä¸åŒæ¨¡æ€æ•°æ®\n",
    "        \"\"\"\n",
    "        # æ”¶é›†æ‰€æœ‰æ•°æ®å¹¶åˆ›å»ºå‚è€ƒæ—¶é—´çº¿\n",
    "        all_data = []\n",
    "        for data_list in data_by_modality.values():\n",
    "            all_data.extend(data_list)\n",
    "            \n",
    "        if not all_data:\n",
    "            return []\n",
    "            \n",
    "        self.create_reference_timeline(all_data)\n",
    "        \n",
    "        # ä¸ºæ¯ä¸ªå‚è€ƒæ—¶é—´ç‚¹æ‰¾åˆ°æœ€æ¥è¿‘çš„æ•°æ®\n",
    "        aligned_groups = []\n",
    "        \n",
    "        for ref_time in self.reference_timeline:\n",
    "            aligned_group = {}\n",
    "            \n",
    "            for modality, data_list in data_by_modality.items():\n",
    "                # æ‰¾åˆ°æœ€æ¥è¿‘å‚è€ƒæ—¶é—´çš„æ•°æ®\n",
    "                closest_data = self._find_closest_data(data_list, ref_time)\n",
    "                \n",
    "                if closest_data and abs(closest_data.timestamp - ref_time) <= self.alignment_tolerance:\n",
    "                    aligned_group[modality] = closest_data\n",
    "            \n",
    "            # åªä¿ç•™è‡³å°‘æœ‰ä¸€ä¸ªæ¨¡æ€æ•°æ®çš„æ—¶é—´ç‚¹\n",
    "            if aligned_group:\n",
    "                aligned_groups.append(aligned_group)\n",
    "        \n",
    "        self.aligned_groups = aligned_groups\n",
    "        \n",
    "        logger.info(f\"å¯¹é½å®Œæˆ: {len(aligned_groups)} ä¸ªæ—¶é—´ç»„\")\n",
    "        \n",
    "        return aligned_groups\n",
    "    \n",
    "    def _find_closest_data(self, data_list: List[ModalityData], target_time: float) -> Optional[ModalityData]:\n",
    "        \"\"\"\n",
    "        åœ¨æ•°æ®åˆ—è¡¨ä¸­æ‰¾åˆ°æœ€æ¥è¿‘ç›®æ ‡æ—¶é—´çš„æ•°æ®\n",
    "        \n",
    "        Args:\n",
    "            data_list: æ•°æ®åˆ—è¡¨\n",
    "            target_time: ç›®æ ‡æ—¶é—´\n",
    "            \n",
    "        Returns:\n",
    "            æœ€æ¥è¿‘çš„æ•°æ®é¡¹\n",
    "        \"\"\"\n",
    "        if not data_list:\n",
    "            return None\n",
    "            \n",
    "        return min(data_list, key=lambda x: abs(x.timestamp - target_time))\n",
    "    \n",
    "    def interpolate_missing_data(self, aligned_groups: List[Dict[ModalityType, ModalityData]]) -> List[Dict[ModalityType, ModalityData]]:\n",
    "        \"\"\"\n",
    "        å¯¹ç¼ºå¤±çš„æ¨¡æ€æ•°æ®è¿›è¡Œæ’å€¼\n",
    "        \n",
    "        Args:\n",
    "            aligned_groups: å¯¹é½åçš„æ•°æ®ç»„\n",
    "            \n",
    "        Returns:\n",
    "            æ’å€¼åçš„æ•°æ®ç»„\n",
    "        \"\"\"\n",
    "        if not aligned_groups:\n",
    "            return []\n",
    "            \n",
    "        # è·å–æ‰€æœ‰å‡ºç°è¿‡çš„æ¨¡æ€ç±»å‹\n",
    "        all_modalities = set()\n",
    "        for group in aligned_groups:\n",
    "            all_modalities.update(group.keys())\n",
    "        \n",
    "        # ä¸ºæ¯ä¸ªæ¨¡æ€ç»´æŠ¤æœ€è¿‘çš„æœ‰æ•ˆæ•°æ®\n",
    "        last_valid_data = {modality: None for modality in all_modalities}\n",
    "        \n",
    "        interpolated_groups = []\n",
    "        \n",
    "        for i, group in enumerate(aligned_groups):\n",
    "            interpolated_group = dict(group)  # å¤åˆ¶ç°æœ‰æ•°æ®\n",
    "            \n",
    "            # æ›´æ–°æœ€è¿‘çš„æœ‰æ•ˆæ•°æ®\n",
    "            for modality, data in group.items():\n",
    "                last_valid_data[modality] = data\n",
    "            \n",
    "            # ä¸ºç¼ºå¤±çš„æ¨¡æ€æ’å€¼\n",
    "            for modality in all_modalities:\n",
    "                if modality not in interpolated_group and last_valid_data[modality] is not None:\n",
    "                    # åˆ›å»ºæ’å€¼æ•°æ®ï¼ˆç®€å•å¤åˆ¶æœ€è¿‘çš„æœ‰æ•ˆæ•°æ®ï¼‰\n",
    "                    interpolated_data = self._create_interpolated_data(\n",
    "                        last_valid_data[modality], \n",
    "                        self.reference_timeline[i] if i < len(self.reference_timeline) else 0.0\n",
    "                    )\n",
    "                    interpolated_group[modality] = interpolated_data\n",
    "            \n",
    "            interpolated_groups.append(interpolated_group)\n",
    "        \n",
    "        logger.info(f\"æ’å€¼å®Œæˆ: å¤„ç†äº† {len(interpolated_groups)} ä¸ªæ•°æ®ç»„\")\n",
    "        \n",
    "        return interpolated_groups\n",
    "    \n",
    "    def _create_interpolated_data(self, reference_data: ModalityData, new_timestamp: float) -> ModalityData:\n",
    "        \"\"\"\n",
    "        åˆ›å»ºæ’å€¼æ•°æ®\n",
    "        \n",
    "        Args:\n",
    "            reference_data: å‚è€ƒæ•°æ®\n",
    "            new_timestamp: æ–°çš„æ—¶é—´æˆ³\n",
    "            \n",
    "        Returns:\n",
    "            æ’å€¼åçš„æ•°æ®\n",
    "        \"\"\"\n",
    "        return ModalityData(\n",
    "            modality_type=reference_data.modality_type,\n",
    "            data=reference_data.data,  # ç®€å•å¤åˆ¶æ•°æ®\n",
    "            timestamp=new_timestamp,\n",
    "            duration=reference_data.duration,\n",
    "            sequence_id=reference_data.sequence_id,\n",
    "            metadata={**reference_data.metadata, \"interpolated\": True}\n",
    "        )\n",
    "    \n",
    "    def visualize_alignment(self, data_by_modality: Dict[ModalityType, List[ModalityData]]):\n",
    "        \"\"\"\n",
    "        å¯è§†åŒ–æ—¶åºå¯¹é½ç»“æœ\n",
    "        \"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(15, 8))\n",
    "        \n",
    "        colors = {'audio': 'red', 'video': 'green', 'text': 'blue', 'image': 'orange'}\n",
    "        y_positions = {'audio': 3, 'video': 2, 'text': 1, 'image': 0}\n",
    "        \n",
    "        # ç»˜åˆ¶åŸå§‹æ•°æ®\n",
    "        for modality, data_list in data_by_modality.items():\n",
    "            timestamps = [data.timestamp for data in data_list]\n",
    "            y_pos = [y_positions[modality.value]] * len(timestamps)\n",
    "            \n",
    "            ax.scatter(timestamps, y_pos, \n",
    "                      color=colors[modality.value], \n",
    "                      s=50, alpha=0.7, \n",
    "                      label=f'{modality.value} åŸå§‹æ•°æ®')\n",
    "        \n",
    "        # ç»˜åˆ¶å‚è€ƒæ—¶é—´çº¿\n",
    "        if self.reference_timeline:\n",
    "            for ref_time in self.reference_timeline[::5]:  # æ¯5ä¸ªç‚¹æ˜¾ç¤ºä¸€ä¸ª\n",
    "                ax.axvline(x=ref_time, color='gray', linestyle='--', alpha=0.3)\n",
    "        \n",
    "        ax.set_xlabel('æ—¶é—´ (ç§’)')\n",
    "        ax.set_ylabel('æ¨¡æ€ç±»å‹')\n",
    "        ax.set_yticks(list(y_positions.values()))\n",
    "        ax.set_yticklabels(list(y_positions.keys()))\n",
    "        ax.set_title('å¤šæ¨¡æ€æ•°æ®æ—¶åºå¯¹é½å¯è§†åŒ–')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "print(\"âœ… æ—¶åºå¯¹é½å¼•æ“å®ç°å®Œæˆ\")\n",
    "print(\"æ”¯æŒå‚è€ƒæ—¶é—´çº¿åˆ›å»ºã€æ•°æ®å¯¹é½å’Œç¼ºå¤±æ•°æ®æ’å€¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 ç¼“å†²åŒºç®¡ç†å’Œæ•°æ®æµæ§åˆ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiModalBuffer:\n",
    "    \"\"\"\n",
    "    å¤šæ¨¡æ€ç¼“å†²åŒºç®¡ç†å™¨\n",
    "    è´Ÿè´£ç®¡ç†ä¸åŒæ¨¡æ€æ•°æ®çš„ç¼“å†²ã€æµæ§å’Œå†…å­˜ä¼˜åŒ–\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_buffer_size: int = 1000, max_memory_mb: float = 100.0):\n",
    "        \"\"\"\n",
    "        åˆå§‹åŒ–å¤šæ¨¡æ€ç¼“å†²åŒº\n",
    "        \n",
    "        Args:\n",
    "            max_buffer_size: æ¯ä¸ªæ¨¡æ€çš„æœ€å¤§ç¼“å†²åŒºå¤§å°\n",
    "            max_memory_mb: æœ€å¤§å†…å­˜ä½¿ç”¨é‡ï¼ˆMBï¼‰\n",
    "        \"\"\"\n",
    "        self.max_buffer_size = max_buffer_size\n",
    "        self.max_memory_bytes = max_memory_mb * 1024 * 1024\n",
    "        \n",
    "        # ä¸ºæ¯ä¸ªæ¨¡æ€åˆ›å»ºç‹¬ç«‹çš„ç¼“å†²åŒº\n",
    "        self.buffers = {\n",
    "            modality: queue.Queue(maxsize=max_buffer_size) \n",
    "            for modality in ModalityType\n",
    "        }\n",
    "        \n",
    "        # ç¼“å†²åŒºç»Ÿè®¡ä¿¡æ¯\n",
    "        self.buffer_stats = {\n",
    "            modality: {\n",
    "                'total_items': 0,\n",
    "                'current_size': 0,\n",
    "                'memory_usage': 0,\n",
    "                'dropped_items': 0,\n",
    "                'last_access_time': 0.0\n",
    "            } for modality in ModalityType\n",
    "        }\n",
    "        \n",
    "        # æµæ§å‚æ•°\n",
    "        self.flow_control = {\n",
    "            'enabled': True,\n",
    "            'high_watermark': 0.8,  # ç¼“å†²åŒºä½¿ç”¨ç‡è¶…è¿‡80%æ—¶å¯åŠ¨æµæ§\n",
    "            'low_watermark': 0.6,   # ç¼“å†²åŒºä½¿ç”¨ç‡ä½äº60%æ—¶è§£é™¤æµæ§\n",
    "            'throttle_factor': 0.5  # æµæ§æ—¶çš„å¤„ç†é€Ÿåº¦å› å­\n",
    "        }\n",
    "        \n",
    "        self._lock = threading.RLock()  # çº¿ç¨‹å®‰å…¨é”\n",
    "        \n",
    "    def put_data(self, data: ModalityData, timeout: float = 1.0) -> bool:\n",
    "        \"\"\"\n",
    "        å‘ç¼“å†²åŒºæ·»åŠ æ•°æ®\n",
    "        \n",
    "        Args:\n",
    "            data: è¦æ·»åŠ çš„æ•°æ®\n",
    "            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰\n",
    "            \n",
    "        Returns:\n",
    "            æ˜¯å¦æˆåŠŸæ·»åŠ \n",
    "        \"\"\"\n",
    "        with self._lock:\n",
    "            modality = data.modality_type\n",
    "            buffer = self.buffers[modality]\n",
    "            \n",
    "            # æ£€æŸ¥å†…å­˜ä½¿ç”¨é‡\n",
    "            if not self._check_memory_limit(data):\n",
    "                logger.warning(f\"å†…å­˜ä¸è¶³ï¼Œä¸¢å¼ƒ {modality.value} æ•°æ®\")\n",
    "                self.buffer_stats[modality]['dropped_items'] += 1\n",
    "                return False\n",
    "            \n",
    "            try:\n",
    "                # å°è¯•æ·»åŠ æ•°æ®åˆ°ç¼“å†²åŒº\n",
    "                buffer.put(data, timeout=timeout)\n",
    "                \n",
    "                # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯\n",
    "                self.buffer_stats[modality]['total_items'] += 1\n",
    "                self.buffer_stats[modality]['current_size'] = buffer.qsize()\n",
    "                self.buffer_stats[modality]['memory_usage'] += self._estimate_data_size(data)\n",
    "                self.buffer_stats[modality]['last_access_time'] = time.time()\n",
    "                \n",
    "                logger.debug(f\"æ·»åŠ  {modality.value} æ•°æ®åˆ°ç¼“å†²åŒºï¼Œå½“å‰å¤§å°: {buffer.qsize()}\")\n",
    "                return True\n",
    "                \n",
    "            except queue.Full:\n",
    "                # ç¼“å†²åŒºæ»¡ï¼Œå°è¯•æ¸…ç†æ—§æ•°æ®\n",
    "                if self._cleanup_old_data(modality):\n",
    "                    return self.put_data(data, timeout)  # é€’å½’é‡è¯•\n",
    "                else:\n",
    "                    logger.warning(f\"{modality.value} ç¼“å†²åŒºå·²æ»¡ï¼Œä¸¢å¼ƒæ•°æ®\")\n",
    "                    self.buffer_stats[modality]['dropped_items'] += 1\n",
    "                    return False\n",
    "    \n",
    "    def get_data(self, modality: ModalityType, timeout: float = 0.1) -> Optional[ModalityData]:\n",
    "        \"\"\"\n",
    "        ä»ç¼“å†²åŒºè·å–æ•°æ®\n",
    "        \n",
    "        Args:\n",
    "            modality: æ¨¡æ€ç±»å‹\n",
    "            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰\n",
    "            \n",
    "        Returns:\n",
    "            è·å–çš„æ•°æ®ï¼Œå¦‚æœæ²¡æœ‰æ•°æ®åˆ™è¿”å›None\n",
    "        \"\"\"\n",
    "        with self._lock:\n",
    "            buffer = self.buffers[modality]\n",
    "            \n",
    "            try:\n",
    "                data = buffer.get(timeout=timeout)\n",
    "                \n",
    "                # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯\n",
    "                self.buffer_stats[modality]['current_size'] = buffer.qsize()\n",
    "                self.buffer_stats[modality]['memory_usage'] -= self._estimate_data_size(data)\n",
    "                self.buffer_stats[modality]['last_access_time'] = time.time()\n",
    "                \n",
    "                logger.debug(f\"ä» {modality.value} ç¼“å†²åŒºè·å–æ•°æ®ï¼Œå‰©ä½™: {buffer.qsize()}\")\n",
    "                return data\n",
    "                \n",
    "            except queue.Empty:\n",
    "                return None\n",
    "    \n",
    "    def get_pending_data(self) -> Dict[ModalityType, List[ModalityData]]:\n",
    "        \"\"\"\n",
    "        è·å–æ‰€æœ‰å¾…å¤„ç†çš„æ•°æ®ï¼ˆä¸ä»ç¼“å†²åŒºç§»é™¤ï¼‰\n",
    "        \n",
    "        Returns:\n",
    "            æŒ‰æ¨¡æ€åˆ†ç»„çš„å¾…å¤„ç†æ•°æ®\n",
    "        \"\"\"\n",
    "        with self._lock:\n",
    "            pending_data = {}\n",
    "            \n",
    "            for modality, buffer in self.buffers.items():\n",
    "                # å°†é˜Ÿåˆ—è½¬æ¢ä¸ºåˆ—è¡¨ï¼ˆä¸ç§»é™¤æ•°æ®ï¼‰\n",
    "                data_list = []\n",
    "                temp_list = []\n",
    "                \n",
    "                # ä¸´æ—¶å–å‡ºæ‰€æœ‰æ•°æ®\n",
    "                while not buffer.empty():\n",
    "                    try:\n",
    "                        data = buffer.get_nowait()\n",
    "                        data_list.append(data)\n",
    "                        temp_list.append(data)\n",
    "                    except queue.Empty:\n",
    "                        break\n",
    "                \n",
    "                # å°†æ•°æ®æ”¾å›é˜Ÿåˆ—\n",
    "                for data in temp_list:\n",
    "                    try:\n",
    "                        buffer.put_nowait(data)\n",
    "                    except queue.Full:\n",
    "                        break\n",
    "                \n",
    "                pending_data[modality] = data_list\n",
    "            \n",
    "            return pending_data\n",
    "    \n",
    "    def _check_memory_limit(self, new_data: ModalityData) -> bool:\n",
    "        \"\"\"\n",
    "        æ£€æŸ¥æ·»åŠ æ–°æ•°æ®æ˜¯å¦ä¼šè¶…è¿‡å†…å­˜é™åˆ¶\n",
    "        \"\"\"\n",
    "        current_memory = sum(stats['memory_usage'] for stats in self.buffer_stats.values())\n",
    "        new_data_size = self._estimate_data_size(new_data)\n",
    "        \n",
    "        return (current_memory + new_data_size) <= self.max_memory_bytes\n",
    "    \n",
    "    def _estimate_data_size(self, data: ModalityData) -> int:\n",
    "        \"\"\"\n",
    "        ä¼°ç®—æ•°æ®å¤§å°ï¼ˆå­—èŠ‚ï¼‰\n",
    "        \"\"\"\n",
    "        # ç®€åŒ–çš„å¤§å°ä¼°ç®—\n",
    "        base_size = 1024  # åŸºç¡€å¼€é”€\n",
    "        \n",
    "        if data.modality_type == ModalityType.TEXT:\n",
    "            return base_size + len(str(data.data)) * 4  # å‡è®¾æ¯ä¸ªå­—ç¬¦4å­—èŠ‚\n",
    "        elif data.modality_type == ModalityType.AUDIO:\n",
    "            return base_size + int(data.duration * 44100 * 2)  # 44.1kHz, 16-bit\n",
    "        elif data.modality_type == ModalityType.VIDEO:\n",
    "            return base_size + int(data.duration * 1920 * 1080 * 3)  # 1080p, RGB\n",
    "        else:\n",
    "            return base_size + 1920 * 1080 * 3  # é»˜è®¤å›¾åƒå¤§å°\n",
    "    \n",
    "    def _cleanup_old_data(self, modality: ModalityType) -> bool:\n",
    "        \"\"\"\n",
    "        æ¸…ç†æŒ‡å®šæ¨¡æ€çš„æ—§æ•°æ®\n",
    "        \n",
    "        Returns:\n",
    "            æ˜¯å¦æˆåŠŸæ¸…ç†å‡ºç©ºé—´\n",
    "        \"\"\"\n",
    "        buffer = self.buffers[modality]\n",
    "        current_time = time.time()\n",
    "        \n",
    "        # ç§»é™¤è¶…è¿‡5ç§’çš„æ—§æ•°æ®\n",
    "        cleaned_count = 0\n",
    "        temp_data = []\n",
    "        \n",
    "        while not buffer.empty():\n",
    "            try:\n",
    "                data = buffer.get_nowait()\n",
    "                if current_time - data.timestamp > 5.0:  # 5ç§’è¶…æ—¶\n",
    "                    cleaned_count += 1\n",
    "                    self.buffer_stats[modality]['memory_usage'] -= self._estimate_data_size(data)\n",
    "                else:\n",
    "                    temp_data.append(data)\n",
    "            except queue.Empty:\n",
    "                break\n",
    "        \n",
    "        # å°†æœªè¿‡æœŸçš„æ•°æ®æ”¾å›\n",
    "        for data in temp_data:\n",
    "            try:\n",
    "                buffer.put_nowait(data)\n",
    "            except queue.Full:\n",
    "                break\n",
    "        \n",
    "        if cleaned_count > 0:\n",
    "            logger.info(f\"æ¸…ç†äº† {cleaned_count} ä¸ªè¿‡æœŸçš„ {modality.value} æ•°æ®\")\n",
    "            self.buffer_stats[modality]['current_size'] = buffer.qsize()\n",
    "        \n",
    "        return cleaned_count > 0\n",
    "    \n",
    "    def get_buffer_status(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        è·å–ç¼“å†²åŒºçŠ¶æ€ä¿¡æ¯\n",
    "        \"\"\"\n",
    "        with self._lock:\n",
    "            status = {\n",
    "                'total_memory_usage': sum(stats['memory_usage'] for stats in self.buffer_stats.values()),\n",
    "                'max_memory_bytes': self.max_memory_bytes,\n",
    "                'modality_stats': {}\n",
    "            }\n",
    "            \n",
    "            for modality, stats in self.buffer_stats.items():\n",
    "                buffer_size = self.buffers[modality].qsize()\n",
    "                usage_ratio = buffer_size / self.max_buffer_size\n",
    "                \n",
    "                status['modality_stats'][modality.value] = {\n",
    "                    **stats,\n",
    "                    'usage_ratio': usage_ratio,\n",
    "                    'is_flow_controlled': usage_ratio > self.flow_control['high_watermark']\n",
    "                }\n",
    "            \n",
    "            return status\n",
    "\n",
    "print(\"âœ… å¤šæ¨¡æ€ç¼“å†²åŒºç®¡ç†å™¨å®ç°å®Œæˆ\")\n",
    "print(\"æ”¯æŒå†…å­˜ç®¡ç†ã€æµæ§ã€æ•°æ®æ¸…ç†å’Œçº¿ç¨‹å®‰å…¨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. æºç å®ç°åˆ†æ\n",
    "\n",
    "### 3.1 TDMæ ¸å¿ƒå¼•æ“å®ç°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TDMEngine:\n",
    "    \"\"\"\n",
    "    æ—¶åˆ†å¤ç”¨æ ¸å¿ƒå¼•æ“\n",
    "    æ•´åˆè°ƒåº¦å™¨ã€å¯¹é½å¼•æ“å’Œç¼“å†²åŒºç®¡ç†å™¨ï¼Œæä¾›å®Œæ•´çš„TDMåŠŸèƒ½\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 slice_duration: float = 0.1,\n",
    "                 alignment_tolerance: float = 0.05,\n",
    "                 max_buffer_size: int = 1000,\n",
    "                 max_memory_mb: float = 100.0):\n",
    "        \"\"\"\n",
    "        åˆå§‹åŒ–TDMå¼•æ“\n",
    "        \n",
    "        Args:\n",
    "            slice_duration: æ—¶é—´ç‰‡æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰\n",
    "            alignment_tolerance: æ—¶åºå¯¹é½å®¹å·®ï¼ˆç§’ï¼‰\n",
    "            max_buffer_size: æœ€å¤§ç¼“å†²åŒºå¤§å°\n",
    "            max_memory_mb: æœ€å¤§å†…å­˜ä½¿ç”¨é‡ï¼ˆMBï¼‰\n",
    "        \"\"\"\n",
    "        # åˆå§‹åŒ–å„ä¸ªç»„ä»¶\n",
    "        self.scheduler = TimeSliceScheduler(slice_duration)\n",
    "        self.alignment_engine = TemporalAlignmentEngine(alignment_tolerance)\n",
    "        self.buffer_manager = MultiModalBuffer(max_buffer_size, max_memory_mb)\n",
    "        \n",
    "        # å¼•æ“çŠ¶æ€\n",
    "        self.is_running = False\n",
    "        self.processing_thread = None\n",
    "        self.stats = {\n",
    "            'processed_slices': 0,\n",
    "            'aligned_groups': 0,\n",
    "            'total_latency': 0.0,\n",
    "            'average_latency': 0.0\n",
    "        }\n",
    "        \n",
    "        # å›è°ƒå‡½æ•°\n",
    "        self.data_processor_callback = None\n",
    "        self.error_handler_callback = None\n",
    "        \n",
    "        self._lock = threading.RLock()\n",
    "        \n",
    "    def set_data_processor(self, callback):\n",
    "        \"\"\"\n",
    "        è®¾ç½®æ•°æ®å¤„ç†å›è°ƒå‡½æ•°\n",
    "        \n",
    "        Args:\n",
    "            callback: å¤„ç†å¯¹é½åæ•°æ®çš„å›è°ƒå‡½æ•°\n",
    "                     ç­¾å: callback(aligned_data: Dict[ModalityType, ModalityData]) -> Any\n",
    "        \"\"\"\n",
    "        self.data_processor_callback = callback\n",
    "        \n",
    "    def set_error_handler(self, callback):\n",
    "        \"\"\"\n",
    "        è®¾ç½®é”™è¯¯å¤„ç†å›è°ƒå‡½æ•°\n",
    "        \n",
    "        Args:\n",
    "            callback: é”™è¯¯å¤„ç†å›è°ƒå‡½æ•°\n",
    "                     ç­¾å: callback(error: Exception, context: Dict) -> None\n",
    "        \"\"\"\n",
    "        self.error_handler_callback = callback\n",
    "        \n",
    "    def add_data(self, data: ModalityData) -> bool:\n",
    "        \"\"\"\n",
    "        æ·»åŠ æ•°æ®åˆ°TDMå¼•æ“\n",
    "        \n",
    "        Args:\n",
    "            data: è¦æ·»åŠ çš„æ¨¡æ€æ•°æ®\n",
    "            \n",
    "        Returns:\n",
    "            æ˜¯å¦æˆåŠŸæ·»åŠ \n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self.buffer_manager.put_data(data)\n",
    "        except Exception as e:\n",
    "            self._handle_error(e, {'operation': 'add_data', 'data': data})\n",
    "            return False\n",
    "    \n",
    "    def start_processing(self):\n",
    "        \"\"\"\n",
    "        å¯åŠ¨TDMå¤„ç†çº¿ç¨‹\n",
    "        \"\"\"\n",
    "        with self._lock:\n",
    "            if self.is_running:\n",
    "                logger.warning(\"TDMå¼•æ“å·²åœ¨è¿è¡Œä¸­\")\n",
    "                return\n",
    "                \n",
    "            self.is_running = True\n",
    "            self.processing_thread = threading.Thread(target=self._processing_loop, daemon=True)\n",
    "            self.processing_thread.start()\n",
    "            \n",
    "            logger.info(\"TDMå¼•æ“å¯åŠ¨æˆåŠŸ\")\n",
    "    \n",
    "    def stop_processing(self):\n",
    "        \"\"\"\n",
    "        åœæ­¢TDMå¤„ç†çº¿ç¨‹\n",
    "        \"\"\"\n",
    "        with self._lock:\n",
    "            if not self.is_running:\n",
    "                return\n",
    "                \n",
    "            self.is_running = False\n",
    "            \n",
    "            if self.processing_thread and self.processing_thread.is_alive():\n",
    "                self.processing_thread.join(timeout=5.0)\n",
    "                \n",
    "            logger.info(\"TDMå¼•æ“å·²åœæ­¢\")\n",
    "    \n",
    "    def _processing_loop(self):\n",
    "        \"\"\"\n",
    "        ä¸»å¤„ç†å¾ªç¯\n",
    "        \"\"\"\n",
    "        logger.info(\"TDMå¤„ç†å¾ªç¯å¼€å§‹\")\n",
    "        \n",
    "        while self.is_running:\n",
    "            try:\n",
    "                slice_start_time = time.time()\n",
    "                \n",
    "                # è·å–å¾…å¤„ç†æ•°æ®\n",
    "                pending_data = self.buffer_manager.get_pending_data()\n",
    "                \n",
    "                if any(data_list for data_list in pending_data.values()):\n",
    "                    # é€‰æ‹©å½“å‰æ—¶é—´ç‰‡è¦å¤„ç†çš„æ¨¡æ€\n",
    "                    selected_modality = self.scheduler.calculate_next_modality(pending_data)\n",
    "                    \n",
    "                    if selected_modality:\n",
    "                        # ä»ç¼“å†²åŒºè·å–æ•°æ®\n",
    "                        data = self.buffer_manager.get_data(selected_modality)\n",
    "                        \n",
    "                        if data:\n",
    "                            # å¤„ç†å•ä¸ªæ¨¡æ€æ•°æ®\n",
    "                            self._process_single_modality_data(data)\n",
    "                            \n",
    "                            # å°è¯•è¿›è¡Œå¤šæ¨¡æ€å¯¹é½\n",
    "                            self._attempt_multimodal_alignment()\n",
    "                \n",
    "                # æ¨è¿›åˆ°ä¸‹ä¸€ä¸ªæ—¶é—´ç‰‡\n",
    "                self.scheduler.advance_time()\n",
    "                self.stats['processed_slices'] += 1\n",
    "                \n",
    "                # è®¡ç®—å»¶è¿Ÿ\n",
    "                slice_latency = time.time() - slice_start_time\n",
    "                self.stats['total_latency'] += slice_latency\n",
    "                self.stats['average_latency'] = self.stats['total_latency'] / self.stats['processed_slices']\n",
    "                \n",
    "                # æ§åˆ¶å¤„ç†é¢‘ç‡\n",
    "                sleep_time = max(0, self.scheduler.slice_duration - slice_latency)\n",
    "                if sleep_time > 0:\n",
    "                    time.sleep(sleep_time)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                self._handle_error(e, {'operation': 'processing_loop'})\n",
    "                time.sleep(0.1)  # é”™è¯¯åçŸ­æš‚ä¼‘æ¯\n",
    "        \n",
    "        logger.info(\"TDMå¤„ç†å¾ªç¯ç»“æŸ\")\n",
    "    \n",
    "    def _process_single_modality_data(self, data: ModalityData):\n",
    "        \"\"\"\n",
    "        å¤„ç†å•ä¸ªæ¨¡æ€æ•°æ®\n",
    "        \n",
    "        Args:\n",
    "            data: è¦å¤„ç†çš„æ•°æ®\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # è¿™é‡Œå¯ä»¥æ·»åŠ å•æ¨¡æ€é¢„å¤„ç†é€»è¾‘\n",
    "            logger.debug(f\"å¤„ç† {data.modality_type.value} æ•°æ®: {data.timestamp:.3f}s\")\n",
    "            \n",
    "            # å¦‚æœæœ‰æ•°æ®å¤„ç†å›è°ƒï¼Œè°ƒç”¨å®ƒ\n",
    "            if self.data_processor_callback:\n",
    "                self.data_processor_callback({data.modality_type: data})\n",
    "                \n",
    "        except Exception as e:\n",
    "            self._handle_error(e, {'operation': 'process_single_modality', 'data': data})\n",
    "    \n",
    "    def _attempt_multimodal_alignment(self):\n",
    "        \"\"\"\n",
    "        å°è¯•è¿›è¡Œå¤šæ¨¡æ€å¯¹é½\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # è·å–æ‰€æœ‰å¾…å¤„ç†æ•°æ®\n",
    "            pending_data = self.buffer_manager.get_pending_data()\n",
    "            \n",
    "            # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„æ•°æ®è¿›è¡Œå¯¹é½\n",
    "            total_data_count = sum(len(data_list) for data_list in pending_data.values())\n",
    "            \n",
    "            if total_data_count >= 3:  # è‡³å°‘éœ€è¦3ä¸ªæ•°æ®ç‚¹æ‰è¿›è¡Œå¯¹é½\n",
    "                # æ‰§è¡Œæ—¶åºå¯¹é½\n",
    "                aligned_groups = self.alignment_engine.align_modality_data(pending_data)\n",
    "                \n",
    "                if aligned_groups:\n",
    "                    self.stats['aligned_groups'] += len(aligned_groups)\n",
    "                    \n",
    "                    # å¤„ç†å¯¹é½åçš„æ•°æ®ç»„\n",
    "                    for aligned_group in aligned_groups:\n",
    "                        if self.data_processor_callback:\n",
    "                            self.data_processor_callback(aligned_group)\n",
    "                            \n",
    "                    logger.debug(f\"å®Œæˆå¤šæ¨¡æ€å¯¹é½: {len(aligned_groups)} ä¸ªæ•°æ®ç»„\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            self._handle_error(e, {'operation': 'multimodal_alignment'})\n",
    "    \n",
    "    def _handle_error(self, error: Exception, context: Dict):\n",
    "        \"\"\"\n",
    "        å¤„ç†é”™è¯¯\n",
    "        \n",
    "        Args:\n",
    "            error: å‘ç”Ÿçš„é”™è¯¯\n",
    "            context: é”™è¯¯ä¸Šä¸‹æ–‡ä¿¡æ¯\n",
    "        \"\"\"\n",
    "        logger.error(f\"TDMå¼•æ“é”™è¯¯: {error}, ä¸Šä¸‹æ–‡: {context}\")\n",
    "        \n",
    "        if self.error_handler_callback:\n",
    "            try:\n",
    "                self.error_handler_callback(error, context)\n",
    "            except Exception as callback_error:\n",
    "                logger.error(f\"é”™è¯¯å¤„ç†å›è°ƒå¤±è´¥: {callback_error}\")\n",
    "    \n",
    "    def get_engine_status(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        è·å–å¼•æ“çŠ¶æ€ä¿¡æ¯\n",
    "        \"\"\"\n",
    "        with self._lock:\n",
    "            return {\n",
    "                'is_running': self.is_running,\n",
    "                'stats': dict(self.stats),\n",
    "                'scheduler_status': self.scheduler.get_scheduler_status(),\n",
    "                'buffer_status': self.buffer_manager.get_buffer_status()\n",
    "            }\n",
    "\n",
    "print(\"âœ… TDMæ ¸å¿ƒå¼•æ“å®ç°å®Œæˆ\")\n",
    "print(\"é›†æˆäº†è°ƒåº¦å™¨ã€å¯¹é½å¼•æ“å’Œç¼“å†²åŒºç®¡ç†å™¨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. å®é™…åº”ç”¨ç¤ºä¾‹\n",
    "\n",
    "### 4.1 å®æ—¶å¤šæ¨¡æ€å¯¹è¯åœºæ™¯æ¼”ç¤º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiModalConversationDemo:\n",
    "    \"\"\"\n",
    "    å¤šæ¨¡æ€å¯¹è¯æ¼”ç¤º\n",
    "    å±•ç¤ºTDMåœ¨å®æ—¶å¯¹è¯åœºæ™¯ä¸­çš„åº”ç”¨\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # åˆå§‹åŒ–TDMå¼•æ“\n",
    "        self.tdm_engine = TDMEngine(\n",
    "            slice_duration=0.1,      # 100msæ—¶é—´ç‰‡\n",
    "            alignment_tolerance=0.05, # 50mså¯¹é½å®¹å·®\n",
    "            max_buffer_size=500,     # è¾ƒå°çš„ç¼“å†²åŒºç”¨äºæ¼”ç¤º\n",
    "            max_memory_mb=50.0       # 50MBå†…å­˜é™åˆ¶\n",
    "        )\n",
    "        \n",
    "        # è®¾ç½®æ•°æ®å¤„ç†å›è°ƒ\n",
    "        self.tdm_engine.set_data_processor(self._process_aligned_data)\n",
    "        self.tdm_engine.set_error_handler(self._handle_error)\n",
    "        \n",
    "        # æ¼”ç¤ºæ•°æ®\n",
    "        self.processed_results = []\n",
    "        self.conversation_log = []\n",
    "        \n",
    "    def _process_aligned_data(self, aligned_data: Dict[ModalityType, ModalityData]):\n",
    "        \"\"\"\n",
    "        å¤„ç†å¯¹é½åçš„å¤šæ¨¡æ€æ•°æ®\n",
    "        \n",
    "        Args:\n",
    "            aligned_data: å¯¹é½åçš„æ•°æ®å­—å…¸\n",
    "        \"\"\"\n",
    "        timestamp = time.time()\n",
    "        modalities = list(aligned_data.keys())\n",
    "        \n",
    "        # æ¨¡æ‹Ÿå¤šæ¨¡æ€ç†è§£å’Œå“åº”ç”Ÿæˆ\n",
    "        response = self._generate_multimodal_response(aligned_data)\n",
    "        \n",
    "        # è®°å½•å¤„ç†ç»“æœ\n",
    "        result = {\n",
    "            'timestamp': timestamp,\n",
    "            'modalities': [m.value for m in modalities],\n",
    "            'response': response,\n",
    "            'data_timestamps': {m.value: data.timestamp for m, data in aligned_data.items()}\n",
    "        }\n",
    "        \n",
    "        self.processed_results.append(result)\n",
    "        self.conversation_log.append(f\"[{timestamp:.3f}] å¤„ç†äº† {', '.join(result['modalities'])} -> {response}\")\n",
    "        \n",
    "        logger.info(f\"å¤šæ¨¡æ€å“åº”: {response} (æ¨¡æ€: {', '.join(result['modalities'])})\")\n",
    "    \n",
    "    def _generate_multimodal_response(self, aligned_data: Dict[ModalityType, ModalityData]) -> str:\n",
    "        \"\"\"\n",
    "        ç”Ÿæˆå¤šæ¨¡æ€å“åº”ï¼ˆæ¨¡æ‹Ÿï¼‰\n",
    "        \n",
    "        Args:\n",
    "            aligned_data: å¯¹é½åçš„æ•°æ®\n",
    "            \n",
    "        Returns:\n",
    "            ç”Ÿæˆçš„å“åº”æ–‡æœ¬\n",
    "        \"\"\"\n",
    "        modalities = set(aligned_data.keys())\n",
    "        \n",
    "        # æ ¹æ®ä¸åŒçš„æ¨¡æ€ç»„åˆç”Ÿæˆä¸åŒçš„å“åº”\n",
    "        if ModalityType.AUDIO in modalities and ModalityType.VIDEO in modalities:\n",
    "            return \"æˆ‘å¬åˆ°äº†æ‚¨çš„å£°éŸ³å¹¶çœ‹åˆ°äº†è§†é¢‘å†…å®¹ï¼Œæ­£åœ¨ç»¼åˆåˆ†æ...\"\n",
    "        elif ModalityType.AUDIO in modalities and ModalityType.TEXT in modalities:\n",
    "            return \"æˆ‘ç†è§£äº†æ‚¨çš„è¯­éŸ³å’Œæ–‡å­—è¾“å…¥ï¼Œè®©æˆ‘ä¸ºæ‚¨æä¾›å›ç­”ã€‚\"\n",
    "        elif ModalityType.VIDEO in modalities and ModalityType.TEXT in modalities:\n",
    "            return \"æˆ‘çœ‹åˆ°äº†è§†é¢‘å†…å®¹å¹¶è¯»å–äº†æ–‡å­—æè¿°ï¼Œæ­£åœ¨å¤„ç†æ‚¨çš„è¯·æ±‚ã€‚\"\n",
    "        elif ModalityType.AUDIO in modalities:\n",
    "            return \"æˆ‘å¬åˆ°äº†æ‚¨çš„è¯­éŸ³ï¼Œæ­£åœ¨è¯†åˆ«å’Œç†è§£å†…å®¹ã€‚\"\n",
    "        elif ModalityType.VIDEO in modalities:\n",
    "            return \"æˆ‘çœ‹åˆ°äº†è§†é¢‘å†…å®¹ï¼Œæ­£åœ¨åˆ†æç”»é¢ä¿¡æ¯ã€‚\"\n",
    "        elif ModalityType.TEXT in modalities:\n",
    "            return \"æˆ‘æ”¶åˆ°äº†æ‚¨çš„æ–‡å­—æ¶ˆæ¯ï¼Œæ­£åœ¨å¤„ç†ã€‚\"\n",
    "        else:\n",
    "            return \"æ”¶åˆ°å¤šæ¨¡æ€è¾“å…¥ï¼Œæ­£åœ¨ç»¼åˆå¤„ç†ã€‚\"\n",
    "    \n",
    "    def _handle_error(self, error: Exception, context: Dict):\n",
    "        \"\"\"\n",
    "        å¤„ç†é”™è¯¯\n",
    "        \"\"\"\n",
    "        error_msg = f\"æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {error}\"\n",
    "        self.conversation_log.append(f\"[ERROR] {error_msg}\")\n",
    "        logger.error(error_msg)\n",
    "    \n",
    "    def simulate_conversation(self, duration: float = 10.0):\n",
    "        \"\"\"\n",
    "        æ¨¡æ‹Ÿå¤šæ¨¡æ€å¯¹è¯\n",
    "        \n",
    "        Args:\n",
    "            duration: æ¨¡æ‹ŸæŒç»­æ—¶é—´ï¼ˆç§’ï¼‰\n",
    "        \"\"\"\n",
    "        print(f\"ğŸ­ å¼€å§‹æ¨¡æ‹Ÿ {duration} ç§’çš„å¤šæ¨¡æ€å¯¹è¯...\")\n",
    "        \n",
    "        # å¯åŠ¨TDMå¼•æ“\n",
    "        self.tdm_engine.start_processing()\n",
    "        \n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            sequence_id = 0\n",
    "            \n",
    "            while time.time() - start_time < duration:\n",
    "                current_time = time.time() - start_time\n",
    "                \n",
    "                # æ¨¡æ‹Ÿä¸åŒç±»å‹çš„è¾“å…¥æ•°æ®\n",
    "                if current_time % 2.0 < 0.1:  # æ¯2ç§’ä¸€æ¬¡éŸ³é¢‘è¾“å…¥\n",
    "                    audio_data = ModalityData(\n",
    "                        modality_type=ModalityType.AUDIO,\n",
    "                        data=f\"éŸ³é¢‘ç‰‡æ®µ_{sequence_id}\",\n",
    "                        timestamp=current_time,\n",
    "                        duration=0.5,\n",
    "                        sequence_id=sequence_id,\n",
    "                        metadata={'sample_rate': 16000, 'channels': 1}\n",
    "                    )\n",
    "                    self.tdm_engine.add_data(audio_data)\n",
    "                \n",
    "                if current_time % 3.0 < 0.1:  # æ¯3ç§’ä¸€æ¬¡è§†é¢‘è¾“å…¥\n",
    "                    video_data = ModalityData(\n",
    "                        modality_type=ModalityType.VIDEO,\n",
    "                        data=f\"è§†é¢‘å¸§_{sequence_id}\",\n",
    "                        timestamp=current_time,\n",
    "                        duration=0.033,  # 30fps\n",
    "                        sequence_id=sequence_id,\n",
    "                        metadata={'width': 640, 'height': 480, 'fps': 30}\n",
    "                    )\n",
    "                    self.tdm_engine.add_data(video_data)\n",
    "                \n",
    "                if current_time % 4.0 < 0.1:  # æ¯4ç§’ä¸€æ¬¡æ–‡æœ¬è¾“å…¥\n",
    "                    text_data = ModalityData(\n",
    "                        modality_type=ModalityType.TEXT,\n",
    "                        data=f\"ç”¨æˆ·æ¶ˆæ¯_{sequence_id}: è¿™æ˜¯ä¸€æ¡æµ‹è¯•æ¶ˆæ¯\",\n",
    "                        timestamp=current_time,\n",
    "                        duration=0.1,\n",
    "                        sequence_id=sequence_id,\n",
    "                        metadata={'language': 'zh-CN', 'encoding': 'utf-8'}\n",
    "                    )\n",
    "                    self.tdm_engine.add_data(text_data)\n",
    "                \n",
    "                sequence_id += 1\n",
    "                time.sleep(0.1)  # 100msé—´éš”\n",
    "        \n",
    "        finally:\n",
    "            # åœæ­¢TDMå¼•æ“\n",
    "            self.tdm_engine.stop_processing()\n",
    "        \n",
    "        print(f\"âœ… æ¨¡æ‹Ÿå®Œæˆï¼Œå¤„ç†äº† {len(self.processed_results)} ä¸ªå¤šæ¨¡æ€å“åº”\")\n",
    "    \n",
    "    def show_results(self):\n",
    "        \"\"\"\n",
    "        æ˜¾ç¤ºæ¼”ç¤ºç»“æœ\n",
    "        \"\"\"\n",
    "        print(\"\\nğŸ“Š å¯¹è¯æ¼”ç¤ºç»“æœ:\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # æ˜¾ç¤ºå¯¹è¯æ—¥å¿—\n",
    "        print(\"\\nğŸ’¬ å¯¹è¯æ—¥å¿—:\")\n",
    "        for log_entry in self.conversation_log[-10:]:  # æ˜¾ç¤ºæœ€å10æ¡\n",
    "            print(f\"  {log_entry}\")\n",
    "        \n",
    "        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯\n",
    "        if self.processed_results:\n",
    "            print(\"\\nğŸ“ˆ å¤„ç†ç»Ÿè®¡:\")\n",
    "            modality_counts = {}\n",
    "            for result in self.processed_results:\n",
    "                for modality in result['modalities']:\n",
    "                    modality_counts[modality] = modality_counts.get(modality, 0) + 1\n",
    "            \n",
    "            for modality, count in modality_counts.items():\n",
    "                print(f\"  â€¢ {modality}: {count} æ¬¡å¤„ç†\")\n",
    "        \n",
    "        # æ˜¾ç¤ºå¼•æ“çŠ¶æ€\n",
    "        engine_status = self.tdm_engine.get_engine_status()\n",
    "        print(\"\\nğŸ”§ å¼•æ“çŠ¶æ€:\")\n",
    "        print(f\"  â€¢ å¤„ç†çš„æ—¶é—´ç‰‡: {engine_status['stats']['processed_slices']}\")\n",
    "        print(f\"  â€¢ å¯¹é½çš„æ•°æ®ç»„: {engine_status['stats']['aligned_groups']}\")\n",
    "        print(f\"  â€¢ å¹³å‡å»¶è¿Ÿ: {engine_status['stats']['average_latency']:.3f}s\")\n",
    "\n",
    "# è¿è¡Œæ¼”ç¤º\n",
    "demo = MultiModalConversationDemo()\n",
    "demo.simulate_conversation(duration=5.0)  # 5ç§’æ¼”ç¤º\n",
    "demo.show_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 æ€§èƒ½æµ‹è¯•å’ŒåŸºå‡†å¯¹æ¯”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TDMPerformanceBenchmark:\n",
    "    \"\"\"\n",
    "    TDMæ€§èƒ½åŸºå‡†æµ‹è¯•\n",
    "    å¯¹æ¯”TDMæ–¹æ³•ä¸ä¼ ç»Ÿæ–¹æ³•çš„æ€§èƒ½å·®å¼‚\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.test_results = {\n",
    "            'tdm_method': {},\n",
    "            'traditional_method': {},\n",
    "            'comparison': {}\n",
    "        }\n",
    "    \n",
    "    def generate_test_data(self, duration: float, data_rate: Dict[ModalityType, float]) -> Dict[ModalityType, List[ModalityData]]:\n",
    "        \"\"\"\n",
    "        ç”Ÿæˆæµ‹è¯•æ•°æ®\n",
    "        \n",
    "        Args:\n",
    "            duration: æµ‹è¯•æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰\n",
    "            data_rate: æ¯ä¸ªæ¨¡æ€çš„æ•°æ®ç”Ÿæˆé¢‘ç‡ï¼ˆHzï¼‰\n",
    "            \n",
    "        Returns:\n",
    "            æŒ‰æ¨¡æ€åˆ†ç»„çš„æµ‹è¯•æ•°æ®\n",
    "        \"\"\"\n",
    "        test_data = {modality: [] for modality in ModalityType}\n",
    "        \n",
    "        for modality, rate in data_rate.items():\n",
    "            interval = 1.0 / rate\n",
    "            current_time = 0.0\n",
    "            sequence_id = 0\n",
    "            \n",
    "            while current_time < duration:\n",
    "                # æ·»åŠ ä¸€äº›éšæœºæŠ–åŠ¨æ¥æ¨¡æ‹ŸçœŸå®åœºæ™¯\n",
    "                jitter = np.random.uniform(-0.01, 0.01)  # Â±10msæŠ–åŠ¨\n",
    "                timestamp = current_time + jitter\n",
    "                \n",
    "                data = ModalityData(\n",
    "                    modality_type=modality,\n",
    "                    data=f\"{modality.value}_data_{sequence_id}\",\n",
    "                    timestamp=timestamp,\n",
    "                    duration=interval * 0.8,  # 80%çš„é—´éš”æ—¶é—´ä½œä¸ºæŒç»­æ—¶é—´\n",
    "                    sequence_id=sequence_id,\n",
    "                    metadata={'test_data': True, 'rate': rate}\n",
    "                )\n",
    "                \n",
    "                test_data[modality].append(data)\n",
    "                current_time += interval\n",
    "                sequence_id += 1\n",
    "        \n",
    "        return test_data\n",
    "    \n",
    "    def benchmark_tdm_method(self, test_data: Dict[ModalityType, List[ModalityData]]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        æµ‹è¯•TDMæ–¹æ³•çš„æ€§èƒ½\n",
    "        \n",
    "        Args:\n",
    "            test_data: æµ‹è¯•æ•°æ®\n",
    "            \n",
    "        Returns:\n",
    "            æ€§èƒ½æµ‹è¯•ç»“æœ\n",
    "        \"\"\"\n",
    "        print(\"ğŸš€ æµ‹è¯•TDMæ–¹æ³•æ€§èƒ½...\")\n",
    "        \n",
    "        # åˆ›å»ºTDMå¼•æ“\n",
    "        tdm_engine = TDMEngine(\n",
    "            slice_duration=0.05,     # 50msæ—¶é—´ç‰‡\n",
    "            alignment_tolerance=0.02, # 20mså¯¹é½å®¹å·®\n",
    "            max_buffer_size=1000,\n",
    "            max_memory_mb=100.0\n",
    "        )\n",
    "        \n",
    "        # æ€§èƒ½æŒ‡æ ‡\n",
    "        processed_count = 0\n",
    "        alignment_count = 0\n",
    "        latencies = []\n",
    "        \n",
    "        def data_processor(aligned_data):\n",
    "            nonlocal processed_count, alignment_count\n",
    "            processed_count += 1\n",
    "            if len(aligned_data) > 1:\n",
    "                alignment_count += 1\n",
    "        \n",
    "        tdm_engine.set_data_processor(data_processor)\n",
    "        \n",
    "        # å¼€å§‹æµ‹è¯•\n",
    "        start_time = time.time()\n",
    "        tdm_engine.start_processing()\n",
    "        \n",
    "        try:\n",
    "            # æŒ‰æ—¶é—´é¡ºåºæ·»åŠ æ•°æ®\n",
    "            all_data = []\n",
    "            for data_list in test_data.values():\n",
    "                all_data.extend(data_list)\n",
    "            \n",
    "            all_data.sort(key=lambda x: x.timestamp)\n",
    "            \n",
    "            for data in all_data:\n",
    "                data_start_time = time.time()\n",
    "                success = tdm_engine.add_data(data)\n",
    "                if success:\n",
    "                    latency = time.time() - data_start_time\n",
    "                    latencies.append(latency)\n",
    "                \n",
    "                # æ¨¡æ‹Ÿå®æ—¶æ•°æ®æµ\n",
    "                time.sleep(0.001)  # 1msé—´éš”\n",
    "            \n",
    "            # ç­‰å¾…å¤„ç†å®Œæˆ\n",
    "            time.sleep(1.0)\n",
    "            \n",
    "        finally:\n",
    "            tdm_engine.stop_processing()\n",
    "        \n",
    "        end_time = time.time()\n",
    "        total_time = end_time - start_time\n",
    "        \n",
    "        # è·å–å¼•æ“çŠ¶æ€\n",
    "        engine_status = tdm_engine.get_engine_status()\n",
    "        \n",
    "        results = {\n",
    "            'total_time': total_time,\n",
    "            'processed_count': processed_count,\n",
    "            'alignment_count': alignment_count,\n",
    "            'throughput': processed_count / total_time,\n",
    "            'average_latency': np.mean(latencies) if latencies else 0,\n",
    "            'max_latency': np.max(latencies) if latencies else 0,\n",
    "            'min_latency': np.min(latencies) if latencies else 0,\n",
    "            'latency_std': np.std(latencies) if latencies else 0,\n",
    "            'engine_stats': engine_status['stats'],\n",
    "            'buffer_stats': engine_status['buffer_status']\n",
    "        }\n",
    "        \n",
    "        self.test_results['tdm_method'] = results\n",
    "        return results\n",
    "    \n",
    "    def benchmark_traditional_method(self, test_data: Dict[ModalityType, List[ModalityData]]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        æµ‹è¯•ä¼ ç»Ÿæ–¹æ³•çš„æ€§èƒ½ï¼ˆç®€å•çš„å¹¶è¡Œå¤„ç†ï¼‰\n",
    "        \n",
    "        Args:\n",
    "            test_data: æµ‹è¯•æ•°æ®\n",
    "            \n",
    "        Returns:\n",
    "            æ€§èƒ½æµ‹è¯•ç»“æœ\n",
    "        \"\"\"\n",
    "        print(\"ğŸ”„ æµ‹è¯•ä¼ ç»Ÿæ–¹æ³•æ€§èƒ½...\")\n",
    "        \n",
    "        processed_count = 0\n",
    "        latencies = []\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # ç®€å•çš„å¹¶è¡Œå¤„ç†æ‰€æœ‰æ•°æ®\n",
    "        all_data = []\n",
    "        for data_list in test_data.values():\n",
    "            all_data.extend(data_list)\n",
    "        \n",
    "        all_data.sort(key=lambda x: x.timestamp)\n",
    "        \n",
    "        for data in all_data:\n",
    "            data_start_time = time.time()\n",
    "            \n",
    "            # æ¨¡æ‹Ÿç®€å•çš„æ•°æ®å¤„ç†\n",
    "            time.sleep(0.001)  # 1mså¤„ç†æ—¶é—´\n",
    "            processed_count += 1\n",
    "            \n",
    "            latency = time.time() - data_start_time\n",
    "            latencies.append(latency)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        total_time = end_time - start_time\n",
    "        \n",
    "        results = {\n",
    "            'total_time': total_time,\n",
    "            'processed_count': processed_count,\n",
    "            'alignment_count': 0,  # ä¼ ç»Ÿæ–¹æ³•ä¸è¿›è¡Œå¯¹é½\n",
    "            'throughput': processed_count / total_time,\n",
    "            'average_latency': np.mean(latencies),\n",
    "            'max_latency': np.max(latencies),\n",
    "            'min_latency': np.min(latencies),\n",
    "            'latency_std': np.std(latencies)\n",
    "        }\n",
    "        \n",
    "        self.test_results['traditional_method'] = results\n",
    "        return results\n",
    "    \n",
    "    def run_comprehensive_benchmark(self):\n",
    "        \"\"\"\n",
    "        è¿è¡Œç»¼åˆæ€§èƒ½åŸºå‡†æµ‹è¯•\n",
    "        \"\"\"\n",
    "        print(\"ğŸ“Š å¼€å§‹ç»¼åˆæ€§èƒ½åŸºå‡†æµ‹è¯•...\")\n",
    "        \n",
    "        # æµ‹è¯•é…ç½®\n",
    "        test_configs = [\n",
    "            {\n",
    "                'name': 'ä½é¢‘ç‡æµ‹è¯•',\n",
    "                'duration': 5.0,\n",
    "                'data_rate': {\n",
    "                    ModalityType.AUDIO: 10.0,  # 10Hz\n",
    "                    ModalityType.VIDEO: 5.0,   # 5Hz\n",
    "                    ModalityType.TEXT: 2.0     # 2Hz\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'name': 'ä¸­é¢‘ç‡æµ‹è¯•',\n",
    "                'duration': 5.0,\n",
    "                'data_rate': {\n",
    "                    ModalityType.AUDIO: 50.0,  # 50Hz\n",
    "                    ModalityType.VIDEO: 30.0,  # 30Hz\n",
    "                    ModalityType.TEXT: 10.0    # 10Hz\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'name': 'é«˜é¢‘ç‡æµ‹è¯•',\n",
    "                'duration': 3.0,\n",
    "                'data_rate': {\n",
    "                    ModalityType.AUDIO: 100.0, # 100Hz\n",
    "                    ModalityType.VIDEO: 60.0,  # 60Hz\n",
    "                    ModalityType.TEXT: 20.0    # 20Hz\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        benchmark_results = []\n",
    "        \n",
    "        for config in test_configs:\n",
    "            print(f\"\\nğŸ§ª è¿è¡Œ {config['name']}...\")\n",
    "            \n",
    "            # ç”Ÿæˆæµ‹è¯•æ•°æ®\n",
    "            test_data = self.generate_test_data(config['duration'], config['data_rate'])\n",
    "            \n",
    "            # æµ‹è¯•TDMæ–¹æ³•\n",
    "            tdm_results = self.benchmark_tdm_method(test_data)\n",
    "            \n",
    "            # æµ‹è¯•ä¼ ç»Ÿæ–¹æ³•\n",
    "            traditional_results = self.benchmark_traditional_method(test_data)\n",
    "            \n",
    "            # è®¡ç®—å¯¹æ¯”ç»“æœ\n",
    "            comparison = {\n",
    "                'throughput_ratio': tdm_results['throughput'] / traditional_results['throughput'],\n",
    "                'latency_ratio': tdm_results['average_latency'] / traditional_results['average_latency'],\n",
    "                'alignment_advantage': tdm_results['alignment_count'] > 0\n",
    "            }\n",
    "            \n",
    "            benchmark_results.append({\n",
    "                'config': config,\n",
    "                'tdm_results': tdm_results,\n",
    "                'traditional_results': traditional_results,\n",
    "                'comparison': comparison\n",
    "            })\n",
    "        \n",
    "        self.test_results['comprehensive'] = benchmark_results\n",
    "        return benchmark_results\n",
    "    \n",
    "    def visualize_benchmark_results(self, benchmark_results):\n",
    "        \"\"\"\n",
    "        å¯è§†åŒ–åŸºå‡†æµ‹è¯•ç»“æœ\n",
    "        \"\"\"\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        config_names = [result['config']['name'] for result in benchmark_results]\n",
    "        \n",
    "        # ååé‡å¯¹æ¯”\n",
    "        tdm_throughput = [result['tdm_results']['throughput'] for result in benchmark_results]\n",
    "        traditional_throughput = [result['traditional_results']['throughput'] for result in benchmark_results]\n",
    "        \n",
    "        x = np.arange(len(config_names))\n",
    "        width = 0.35\n",
    "        \n",
    "        ax1.bar(x - width/2, tdm_throughput, width, label='TDMæ–¹æ³•', alpha=0.8)\n",
    "        ax1.bar(x + width/2, traditional_throughput, width, label='ä¼ ç»Ÿæ–¹æ³•', alpha=0.8)\n",
    "        ax1.set_xlabel('æµ‹è¯•é…ç½®')\n",
    "        ax1.set_ylabel('ååé‡ (æ•°æ®/ç§’)')\n",
    "        ax1.set_title('ååé‡å¯¹æ¯”')\n",
    "        ax1.set_xticks(x)\n",
    "        ax1.set_xticklabels(config_names)\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # å»¶è¿Ÿå¯¹æ¯”\n",
    "        tdm_latency = [result['tdm_results']['average_latency'] * 1000 for result in benchmark_results]\n",
    "        traditional_latency = [result['traditional_results']['average_latency'] * 1000 for result in benchmark_results]\n",
    "        \n",
    "        ax2.bar(x - width/2, tdm_latency, width, label='TDMæ–¹æ³•', alpha=0.8)\n",
    "        ax2.bar(x + width/2, traditional_latency, width, label='ä¼ ç»Ÿæ–¹æ³•', alpha=0.8)\n",
    "        ax2.set_xlabel('æµ‹è¯•é…ç½®')\n",
    "        ax2.set_ylabel('å¹³å‡å»¶è¿Ÿ (æ¯«ç§’)')\n",
    "        ax2.set_title('å»¶è¿Ÿå¯¹æ¯”')\n",
    "        ax2.set_xticks(x)\n",
    "        ax2.set_xticklabels(config_names)\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # å¯¹é½æˆåŠŸç‡\n",
    "        alignment_counts = [result['tdm_results']['alignment_count'] for result in benchmark_results]\n",
    "        processed_counts = [result['tdm_results']['processed_count'] for result in benchmark_results]\n",
    "        alignment_rates = [align/proc*100 if proc > 0 else 0 for align, proc in zip(alignment_counts, processed_counts)]\n",
    "        \n",
    "        ax3.bar(config_names, alignment_rates, alpha=0.8, color='green')\n",
    "        ax3.set_xlabel('æµ‹è¯•é…ç½®')\n",
    "        ax3.set_ylabel('å¤šæ¨¡æ€å¯¹é½ç‡ (%)')\n",
    "        ax3.set_title('TDMå¤šæ¨¡æ€å¯¹é½æˆåŠŸç‡')\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        \n",
    "        # æ€§èƒ½æ¯”ç‡\n",
    "        throughput_ratios = [result['comparison']['throughput_ratio'] for result in benchmark_results]\n",
    "        latency_ratios = [result['comparison']['latency_ratio'] for result in benchmark_results]\n",
    "        \n",
    "        ax4.plot(config_names, throughput_ratios, 'o-', label='ååé‡æ¯”ç‡', linewidth=2, markersize=8)\n",
    "        ax4.plot(config_names, latency_ratios, 's-', label='å»¶è¿Ÿæ¯”ç‡', linewidth=2, markersize=8)\n",
    "        ax4.axhline(y=1.0, color='red', linestyle='--', alpha=0.7, label='åŸºå‡†çº¿')\n",
    "        ax4.set_xlabel('æµ‹è¯•é…ç½®')\n",
    "        ax4.set_ylabel('æ¯”ç‡ (TDM/ä¼ ç»Ÿ)')\n",
    "        ax4.set_title('æ€§èƒ½æ¯”ç‡å¯¹æ¯”')\n",
    "        ax4.legend()\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def print_benchmark_summary(self, benchmark_results):\n",
    "        \"\"\"\n",
    "        æ‰“å°åŸºå‡†æµ‹è¯•æ‘˜è¦\n",
    "        \"\"\"\n",
    "        print(\"\\nğŸ“ˆ åŸºå‡†æµ‹è¯•ç»“æœæ‘˜è¦\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        for result in benchmark_results:\n",
    "            config = result['config']\n",
    "            tdm = result['tdm_results']\n",
    "            traditional = result['traditional_results']\n",
    "            comparison = result['comparison']\n",
    "            \n",
    "            print(f\"\\nğŸ§ª {config['name']}:\")\n",
    "            print(f\"  ğŸ“Š TDMæ–¹æ³•:\")\n",
    "            print(f\"    â€¢ ååé‡: {tdm['throughput']:.2f} æ•°æ®/ç§’\")\n",
    "            print(f\"    â€¢ å¹³å‡å»¶è¿Ÿ: {tdm['average_latency']*1000:.2f} ms\")\n",
    "            print(f\"    â€¢ å¤šæ¨¡æ€å¯¹é½: {tdm['alignment_count']} æ¬¡\")\n",
    "            \n",
    "            print(f\"  ğŸ“Š ä¼ ç»Ÿæ–¹æ³•:\")\n",
    "            print(f\"    â€¢ ååé‡: {traditional['throughput']:.2f} æ•°æ®/ç§’\")\n",
    "            print(f\"    â€¢ å¹³å‡å»¶è¿Ÿ: {traditional['average_latency']*1000:.2f} ms\")\n",
    "            \n",
    "            print(f\"  ğŸ“Š å¯¹æ¯”ç»“æœ:\")\n",
    "            print(f\"    â€¢ ååé‡æ¯”ç‡: {comparison['throughput_ratio']:.2f}\")\n",
    "            print(f\"    â€¢ å»¶è¿Ÿæ¯”ç‡: {comparison['latency_ratio']:.2f}\")\n",
    "            print(f\"    â€¢ æ”¯æŒå¤šæ¨¡æ€å¯¹é½: {'æ˜¯' if comparison['alignment_advantage'] else 'å¦'}\")\n",
    "\n",
    "# è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•\n",
    "benchmark = TDMPerformanceBenchmark()\n",
    "results = benchmark.run_comprehensive_benchmark()\n",
    "benchmark.print_benchmark_summary(results)\n",
    "benchmark.visualize_benchmark_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. æŠ€æœ¯ç»†èŠ‚æ·±å…¥åˆ†æ\n",
    "\n",
    "### 5.1 å†…å­˜ç®¡ç†å’Œç¼“å­˜ä¼˜åŒ–ç­–ç•¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TDMOptimizationAnalysis:\n",
    "    \"\"\"\n",
    "    TDMä¼˜åŒ–æŠ€æœ¯åˆ†æ\n",
    "    æ·±å…¥åˆ†æå†…å­˜ç®¡ç†ã€å¹¶å‘å¤„ç†å’Œé”™è¯¯å¤„ç†ç­‰æŠ€æœ¯ç»†èŠ‚\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.optimization_strategies = {\n",
    "            \"å†…å­˜ç®¡ç†ä¼˜åŒ–\": {\n",
    "                \"åˆ†å±‚ç¼“å­˜ç­–ç•¥\": {\n",
    "                    \"L1ç¼“å­˜\": \"çƒ­ç‚¹æ•°æ®ï¼Œå¿«é€Ÿè®¿é—®ï¼Œå°å®¹é‡ï¼ˆ1-10MBï¼‰\",\n",
    "                    \"L2ç¼“å­˜\": \"æ¸©æ•°æ®ï¼Œä¸­ç­‰è®¿é—®é€Ÿåº¦ï¼Œä¸­ç­‰å®¹é‡ï¼ˆ10-100MBï¼‰\",\n",
    "                    \"L3ç¼“å­˜\": \"å†·æ•°æ®ï¼Œè¾ƒæ…¢è®¿é—®ï¼Œå¤§å®¹é‡ï¼ˆ100MB-1GBï¼‰\",\n",
    "                    \"ä¼˜åŠ¿\": \"æ ¹æ®æ•°æ®è®¿é—®é¢‘ç‡ä¼˜åŒ–å†…å­˜ä½¿ç”¨\"\n",
    "                },\n",
    "                \"å†…å­˜æ± ç®¡ç†\": {\n",
    "                    \"é¢„åˆ†é…ç­–ç•¥\": \"å¯åŠ¨æ—¶é¢„åˆ†é…å›ºå®šå¤§å°çš„å†…å­˜æ± \",\n",
    "                    \"åŠ¨æ€æ‰©å±•\": \"æ ¹æ®è´Ÿè½½åŠ¨æ€è°ƒæ•´å†…å­˜æ± å¤§å°\",\n",
    "                    \"å†…å­˜å›æ”¶\": \"å®šæœŸå›æ”¶æœªä½¿ç”¨çš„å†…å­˜å—\",\n",
    "                    \"ä¼˜åŠ¿\": \"å‡å°‘å†…å­˜åˆ†é…/é‡Šæ”¾å¼€é”€ï¼Œæé«˜æ€§èƒ½\"\n",
    "                },\n",
    "                \"æ•°æ®å‹ç¼©\": {\n",
    "                    \"éŸ³é¢‘å‹ç¼©\": \"ä½¿ç”¨OPUSæˆ–AACè¿›è¡Œå®æ—¶éŸ³é¢‘å‹ç¼©\",\n",
    "                    \"è§†é¢‘å‹ç¼©\": \"ä½¿ç”¨H.264/H.265è¿›è¡Œè§†é¢‘å¸§å‹ç¼©\",\n",
    "                    \"æ–‡æœ¬å‹ç¼©\": \"ä½¿ç”¨LZ4è¿›è¡Œå¿«é€Ÿæ–‡æœ¬å‹ç¼©\",\n",
    "                    \"ä¼˜åŠ¿\": \"æ˜¾è‘—å‡å°‘å†…å­˜å ç”¨ï¼Œæé«˜ç¼“å­˜æ•ˆç‡\"\n",
    "                }\n",
    "            },\n",
    "            \"å¹¶å‘å¤„ç†ä¼˜åŒ–\": {\n",
    "                \"æ— é”æ•°æ®ç»“æ„\": {\n",
    "                    \"ç¯å½¢ç¼“å†²åŒº\": \"ä½¿ç”¨åŸå­æ“ä½œå®ç°æ— é”çš„ç¯å½¢ç¼“å†²åŒº\",\n",
    "                    \"CASæ“ä½œ\": \"Compare-And-SwapåŸå­æ“ä½œé¿å…é”ç«äº‰\",\n",
    "                    \"å†…å­˜å±éšœ\": \"ç¡®ä¿å†…å­˜æ“ä½œçš„æ­£ç¡®é¡ºåº\",\n",
    "                    \"ä¼˜åŠ¿\": \"æ¶ˆé™¤é”ç«äº‰ï¼Œæé«˜å¹¶å‘æ€§èƒ½\"\n",
    "                },\n",
    "                \"çº¿ç¨‹æ± ç®¡ç†\": {\n",
    "                    \"å·¥ä½œçªƒå–\": \"ç©ºé—²çº¿ç¨‹å¯ä»¥çªƒå–å…¶ä»–çº¿ç¨‹çš„ä»»åŠ¡\",\n",
    "                    \"ä¼˜å…ˆçº§è°ƒåº¦\": \"æ ¹æ®ä»»åŠ¡ä¼˜å…ˆçº§åˆ†é…çº¿ç¨‹èµ„æº\",\n",
    "                    \"åŠ¨æ€è°ƒæ•´\": \"æ ¹æ®ç³»ç»Ÿè´Ÿè½½åŠ¨æ€è°ƒæ•´çº¿ç¨‹æ•°é‡\",\n",
    "                    \"ä¼˜åŠ¿\": \"æœ€å¤§åŒ–CPUåˆ©ç”¨ç‡ï¼Œå¹³è¡¡è´Ÿè½½\"\n",
    "                },\n",
    "                \"NUMAä¼˜åŒ–\": {\n",
    "                    \"å†…å­˜äº²å’Œæ€§\": \"å°†æ•°æ®åˆ†é…åˆ°å¤„ç†å™¨å°±è¿‘çš„å†…å­˜èŠ‚ç‚¹\",\n",
    "                    \"çº¿ç¨‹ç»‘å®š\": \"å°†çº¿ç¨‹ç»‘å®šåˆ°ç‰¹å®šçš„CPUæ ¸å¿ƒ\",\n",
    "                    \"æ•°æ®å±€éƒ¨æ€§\": \"ä¼˜åŒ–æ•°æ®è®¿é—®æ¨¡å¼ï¼Œå‡å°‘è·¨èŠ‚ç‚¹è®¿é—®\",\n",
    "                    \"ä¼˜åŠ¿\": \"åœ¨å¤šå¤„ç†å™¨ç³»ç»Ÿä¸Šè·å¾—æ›´å¥½çš„æ€§èƒ½\"\n",
    "                }\n",
    "            },\n",
    "            \"å®æ—¶æ€§ä¼˜åŒ–\": {\n",
    "                \"å»¶è¿Ÿæ§åˆ¶\": {\n",
    "                    \"é¢„æµ‹æ€§è°ƒåº¦\": \"åŸºäºå†å²æ•°æ®é¢„æµ‹æœªæ¥çš„å¤„ç†éœ€æ±‚\",\n",
    "                    \"è‡ªé€‚åº”æ—¶é—´ç‰‡\": \"æ ¹æ®ç³»ç»Ÿè´Ÿè½½åŠ¨æ€è°ƒæ•´æ—¶é—´ç‰‡å¤§å°\",\n",
    "                    \"ä¼˜å…ˆçº§æŠ¢å \": \"é«˜ä¼˜å…ˆçº§ä»»åŠ¡å¯ä»¥æŠ¢å ä½ä¼˜å…ˆçº§ä»»åŠ¡\",\n",
    "                    \"ä¼˜åŠ¿\": \"ä¿è¯å…³é”®ä»»åŠ¡çš„å®æ—¶æ€§è¦æ±‚\"\n",
    "                },\n",
    "                \"ç¼“å­˜é¢„çƒ­\": {\n",
    "                    \"æ•°æ®é¢„å–\": \"æå‰åŠ è½½å¯èƒ½éœ€è¦çš„æ•°æ®\",\n",
    "                    \"æ¨¡å‹é¢„çƒ­\": \"æå‰åˆå§‹åŒ–AIæ¨¡å‹å’Œè®¡ç®—å›¾\",\n",
    "                    \"è¿æ¥é¢„å»º\": \"æå‰å»ºç«‹ç½‘ç»œè¿æ¥å’Œèµ„æº\",\n",
    "                    \"ä¼˜åŠ¿\": \"å‡å°‘å†·å¯åŠ¨å»¶è¿Ÿï¼Œæé«˜å“åº”é€Ÿåº¦\"\n",
    "                },\n",
    "                \"æ‰¹å¤„ç†ä¼˜åŒ–\": {\n",
    "                    \"åŠ¨æ€æ‰¹å¤§å°\": \"æ ¹æ®å»¶è¿Ÿè¦æ±‚åŠ¨æ€è°ƒæ•´æ‰¹å¤„ç†å¤§å°\",\n",
    "                    \"æµæ°´çº¿å¤„ç†\": \"å°†å¤„ç†è¿‡ç¨‹åˆ†è§£ä¸ºå¤šä¸ªæµæ°´çº¿é˜¶æ®µ\",\n",
    "                    \"å¼‚æ­¥å¤„ç†\": \"ä½¿ç”¨å¼‚æ­¥I/Oå‡å°‘é˜»å¡ç­‰å¾…\",\n",
    "                    \"ä¼˜åŠ¿\": \"åœ¨ååé‡å’Œå»¶è¿Ÿä¹‹é—´æ‰¾åˆ°æœ€ä½³å¹³è¡¡\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "    def analyze_optimization_strategies(self):\n",
    "        \"\"\"\n",
    "        åˆ†æTDMçš„å„ç§ä¼˜åŒ–ç­–ç•¥\n",
    "        \"\"\"\n",
    "        print(\"ğŸš€ TDMä¼˜åŒ–ç­–ç•¥æ·±åº¦åˆ†æ\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        for category, strategies in self.optimization_strategies.items():\n",
    "            print(f\"\\nğŸ“š {category}:\")\n",
    "            \n",
    "            for strategy_name, details in strategies.items():\n",
    "                print(f\"\\n  ğŸ”§ {strategy_name}:\")\n",
    "                \n",
    "                for key, value in details.items():\n",
    "                    if key == \"ä¼˜åŠ¿\":\n",
    "                        print(f\"    âœ… {key}: {value}\")\n",
    "                    else:\n",
    "                        print(f\"    â€¢ {key}: {value}\")\n",
    "    \n",
    "    def demonstrate_memory_optimization(self):\n",
    "        \"\"\"\n",
    "        æ¼”ç¤ºå†…å­˜ä¼˜åŒ–æŠ€æœ¯\n",
    "        \"\"\"\n",
    "        print(\"\\nğŸ’¾ å†…å­˜ä¼˜åŒ–æŠ€æœ¯æ¼”ç¤º\")\n",
    "        print(\"=\"*30)\n",
    "        \n",
    "        # æ¨¡æ‹Ÿä¸åŒå¤§å°çš„æ•°æ®\n",
    "        data_sizes = [1, 10, 100, 1000, 10000]  # KB\n",
    "        compression_ratios = []\n",
    "        access_times = []\n",
    "        \n",
    "        for size_kb in data_sizes:\n",
    "            # æ¨¡æ‹Ÿæ•°æ®å‹ç¼©\n",
    "            original_size = size_kb * 1024\n",
    "            compressed_size = original_size * np.random.uniform(0.3, 0.7)  # 30-70%å‹ç¼©ç‡\n",
    "            compression_ratio = compressed_size / original_size\n",
    "            compression_ratios.append(compression_ratio)\n",
    "            \n",
    "            # æ¨¡æ‹Ÿè®¿é—®æ—¶é—´ï¼ˆå‹ç¼©æ•°æ®è®¿é—®æ›´å¿«ï¼‰\n",
    "            base_access_time = np.log(size_kb) * 0.1  # åŸºç¡€è®¿é—®æ—¶é—´\n",
    "            compressed_access_time = base_access_time * compression_ratio * 1.2  # è§£å‹å¼€é”€\n",
    "            access_times.append(compressed_access_time)\n",
    "        \n",
    "        # å¯è§†åŒ–ç»“æœ\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        \n",
    "        # å‹ç¼©ç‡\n",
    "        ax1.plot(data_sizes, compression_ratios, 'o-', linewidth=2, markersize=8)\n",
    "        ax1.set_xlabel('æ•°æ®å¤§å° (KB)')\n",
    "        ax1.set_ylabel('å‹ç¼©ç‡')\n",
    "        ax1.set_title('æ•°æ®å‹ç¼©æ•ˆæœ')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.set_xscale('log')\n",
    "        \n",
    "        # è®¿é—®æ—¶é—´\n",
    "        ax2.plot(data_sizes, access_times, 's-', linewidth=2, markersize=8, color='orange')\n",
    "        ax2.set_xlabel('æ•°æ®å¤§å° (KB)')\n",
    "        ax2.set_ylabel('è®¿é—®æ—¶é—´ (ms)')\n",
    "        ax2.set_title('æ•°æ®è®¿é—®æ€§èƒ½')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        ax2.set_xscale('log')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # æ‰“å°ä¼˜åŒ–å»ºè®®\n",
    "        print(\"\\nğŸ’¡ å†…å­˜ä¼˜åŒ–å»ºè®®:\")\n",
    "        avg_compression = np.mean(compression_ratios)\n",
    "        print(f\"  â€¢ å¹³å‡å‹ç¼©ç‡: {avg_compression:.2f} (èŠ‚çœ {(1-avg_compression)*100:.1f}% å†…å­˜)\")\n",
    "        print(f\"  â€¢ å»ºè®®å¯¹ >100KB çš„æ•°æ®å¯ç”¨å‹ç¼©\")\n",
    "        print(f\"  â€¢ ä½¿ç”¨åˆ†å±‚ç¼“å­˜ç­–ç•¥ç®¡ç†ä¸åŒå¤§å°çš„æ•°æ®\")\n",
    "        print(f\"  â€¢ å®šæœŸæ¸…ç†è¶…è¿‡5ç§’çš„è¿‡æœŸæ•°æ®\")\n",
    "    \n",
    "    def analyze_concurrency_patterns(self):\n",
    "        \"\"\"\n",
    "        åˆ†æå¹¶å‘å¤„ç†æ¨¡å¼\n",
    "        \"\"\"\n",
    "        print(\"\\nğŸ”„ å¹¶å‘å¤„ç†æ¨¡å¼åˆ†æ\")\n",
    "        print(\"=\"*30)\n",
    "        \n",
    "        # æ¨¡æ‹Ÿä¸åŒå¹¶å‘çº§åˆ«çš„æ€§èƒ½\n",
    "        thread_counts = [1, 2, 4, 8, 16, 32]\n",
    "        throughputs = []\n",
    "        latencies = []\n",
    "        \n",
    "        for thread_count in thread_counts:\n",
    "            # æ¨¡æ‹Ÿååé‡ï¼ˆè€ƒè™‘çº¿ç¨‹ç«äº‰ï¼‰\n",
    "            if thread_count <= 4:\n",
    "                throughput = thread_count * 100  # çº¿æ€§æ‰©å±•\n",
    "            else:\n",
    "                # è¶…è¿‡4ä¸ªçº¿ç¨‹åï¼Œç”±äºç«äº‰ï¼Œæ‰©å±•æ€§ä¸‹é™\n",
    "                throughput = 400 + (thread_count - 4) * 50 * np.exp(-(thread_count-4)/8)\n",
    "            \n",
    "            throughputs.append(throughput)\n",
    "            \n",
    "            # æ¨¡æ‹Ÿå»¶è¿Ÿï¼ˆæ›´å¤šçº¿ç¨‹å¯èƒ½å¢åŠ å»¶è¿Ÿï¼‰\n",
    "            base_latency = 10  # 10msåŸºç¡€å»¶è¿Ÿ\n",
    "            contention_latency = (thread_count - 1) * 0.5  # ç«äº‰å»¶è¿Ÿ\n",
    "            latency = base_latency + contention_latency\n",
    "            latencies.append(latency)\n",
    "        \n",
    "        # å¯è§†åŒ–å¹¶å‘æ€§èƒ½\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        \n",
    "        # ååé‡æ‰©å±•æ€§\n",
    "        ax1.plot(thread_counts, throughputs, 'o-', linewidth=2, markersize=8, color='green')\n",
    "        ax1.plot(thread_counts, [tc * 100 for tc in thread_counts], '--', alpha=0.5, label='ç†æƒ³çº¿æ€§æ‰©å±•')\n",
    "        ax1.set_xlabel('çº¿ç¨‹æ•°é‡')\n",
    "        ax1.set_ylabel('ååé‡ (æ•°æ®/ç§’)')\n",
    "        ax1.set_title('å¹¶å‘ååé‡æ‰©å±•æ€§')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # å»¶è¿Ÿå˜åŒ–\n",
    "        ax2.plot(thread_counts, latencies, 's-', linewidth=2, markersize=8, color='red')\n",
    "        ax2.set_xlabel('çº¿ç¨‹æ•°é‡')\n",
    "        ax2.set_ylabel('å¹³å‡å»¶è¿Ÿ (ms)')\n",
    "        ax2.set_title('å¹¶å‘å»¶è¿Ÿå˜åŒ–')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # æ‰¾åˆ°æœ€ä¼˜çº¿ç¨‹æ•°\n",
    "        efficiency = [t/l for t, l in zip(throughputs, latencies)]  # ååé‡/å»¶è¿Ÿæ¯”ç‡\n",
    "        optimal_threads = thread_counts[np.argmax(efficiency)]\n",
    "        \n",
    "        print(f\"\\nğŸ¯ å¹¶å‘ä¼˜åŒ–å»ºè®®:\")\n",
    "        print(f\"  â€¢ æœ€ä¼˜çº¿ç¨‹æ•°: {optimal_threads}\")\n",
    "        print(f\"  â€¢ æœ€å¤§ååé‡: {max(throughputs):.0f} æ•°æ®/ç§’\")\n",
    "        print(f\"  â€¢ å»ºè®®ä½¿ç”¨å·¥ä½œçªƒå–ç®—æ³•å¹³è¡¡è´Ÿè½½\")\n",
    "        print(f\"  â€¢ è€ƒè™‘ä½¿ç”¨æ— é”æ•°æ®ç»“æ„å‡å°‘ç«äº‰\")\n",
    "\n",
    "# æ‰§è¡Œä¼˜åŒ–åˆ†æ\n",
    "optimization_analysis = TDMOptimizationAnalysis()\n",
    "optimization_analysis.analyze_optimization_strategies()\n",
    "optimization_analysis.demonstrate_memory_optimization()\n",
    "optimization_analysis.analyze_concurrency_patterns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 ä¸MiniCPM-oå…¶ä»–ç»„ä»¶çš„é›†æˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniCPMIntegrationAnalysis:\n",
    "    \"\"\"\n",
    "    MiniCPM-oé›†æˆåˆ†æ\n",
    "    åˆ†æTDMå¦‚ä½•ä¸MiniCPM-oçš„å…¶ä»–ç»„ä»¶é›†æˆ\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.integration_architecture = {\n",
    "            \"æ ¸å¿ƒç»„ä»¶é›†æˆ\": {\n",
    "                \"è§†è§‰ç¼–ç å™¨ (EVA02)\": {\n",
    "                    \"é›†æˆæ–¹å¼\": \"TDMè°ƒåº¦è§†è§‰å¸§çš„å¤„ç†æ—¶æœº\",\n",
    "                    \"æ•°æ®æµ\": \"å›¾åƒ/è§†é¢‘å¸§ -> EVA02ç¼–ç  -> ç‰¹å¾å‘é‡ -> TDMç¼“å†²åŒº\",\n",
    "                    \"ä¼˜åŒ–ç­–ç•¥\": \"æ‰¹å¤„ç†å¤šä¸ªå¸§ä»¥æé«˜GPUåˆ©ç”¨ç‡\",\n",
    "                    \"æ—¶åºè¦æ±‚\": \"30fpsè§†é¢‘éœ€è¦33mså†…å®Œæˆå¤„ç†\"\n",
    "                },\n",
    "                \"éŸ³é¢‘ç¼–ç å™¨ (Whisper)\": {\n",
    "                    \"é›†æˆæ–¹å¼\": \"TDMç®¡ç†éŸ³é¢‘ç‰‡æ®µçš„å®æ—¶å¤„ç†\",\n",
    "                    \"æ•°æ®æµ\": \"éŸ³é¢‘æµ -> Whisperç¼–ç  -> éŸ³é¢‘ç‰¹å¾ -> TDMç¼“å†²åŒº\",\n",
    "                    \"ä¼˜åŒ–ç­–ç•¥\": \"æµå¼å¤„ç†ï¼Œé¿å…ç­‰å¾…å®Œæ•´éŸ³é¢‘\",\n",
    "                    \"æ—¶åºè¦æ±‚\": \"å®æ—¶è¯­éŸ³éœ€è¦<100mså»¶è¿Ÿ\"\n",
    "                },\n",
    "                \"è¯­è¨€æ¨¡å‹ (Qwen2.5)\": {\n",
    "                    \"é›†æˆæ–¹å¼\": \"TDMåè°ƒå¤šæ¨¡æ€ç‰¹å¾è¾“å…¥åˆ°è¯­è¨€æ¨¡å‹\",\n",
    "                    \"æ•°æ®æµ\": \"å¯¹é½ç‰¹å¾ -> å¤šæ¨¡æ€èåˆ -> Qwen2.5æ¨ç† -> æ–‡æœ¬è¾“å‡º\",\n",
    "                    \"ä¼˜åŒ–ç­–ç•¥\": \"KVç¼“å­˜å¤ç”¨ï¼Œå‡å°‘é‡å¤è®¡ç®—\",\n",
    "                    \"æ—¶åºè¦æ±‚\": \"å¯¹è¯å“åº”éœ€è¦<500mså»¶è¿Ÿ\"\n",
    "                },\n",
    "                \"å¤šæ¨¡æ€æŠ•å½±å™¨\": {\n",
    "                    \"é›†æˆæ–¹å¼\": \"TDMç¡®ä¿ä¸åŒæ¨¡æ€ç‰¹å¾çš„ç»´åº¦å¯¹é½\",\n",
    "                    \"æ•°æ®æµ\": \"åŸå§‹ç‰¹å¾ -> æŠ•å½±å˜æ¢ -> ç»Ÿä¸€ç»´åº¦ç‰¹å¾\",\n",
    "                    \"ä¼˜åŒ–ç­–ç•¥\": \"é¢„è®¡ç®—æŠ•å½±çŸ©é˜µï¼Œå‡å°‘è¿è¡Œæ—¶å¼€é”€\",\n",
    "                    \"æ—¶åºè¦æ±‚\": \"ç‰¹å¾æŠ•å½±éœ€è¦<10ms\"\n",
    "                }\n",
    "            },\n",
    "            \"æ•°æ®æµé›†æˆ\": {\n",
    "                \"è¾“å…¥æ•°æ®æµ\": {\n",
    "                    \"éŸ³é¢‘è¾“å…¥\": \"éº¦å…‹é£ -> éŸ³é¢‘é¢„å¤„ç† -> TDMéŸ³é¢‘ç¼“å†²åŒº\",\n",
    "                    \"è§†é¢‘è¾“å…¥\": \"æ‘„åƒå¤´ -> è§†é¢‘é¢„å¤„ç† -> TDMè§†é¢‘ç¼“å†²åŒº\",\n",
    "                    \"æ–‡æœ¬è¾“å…¥\": \"ç”¨æˆ·è¾“å…¥ -> æ–‡æœ¬é¢„å¤„ç† -> TDMæ–‡æœ¬ç¼“å†²åŒº\",\n",
    "                    \"åŒæ­¥æœºåˆ¶\": \"æ‰€æœ‰è¾“å…¥éƒ½å¸¦æœ‰ç²¾ç¡®çš„æ—¶é—´æˆ³\"\n",
    "                },\n",
    "                \"å¤„ç†æ•°æ®æµ\": {\n",
    "                    \"æ—¶é—´ç‰‡è°ƒåº¦\": \"TDMè°ƒåº¦å™¨å†³å®šå½“å‰å¤„ç†å“ªä¸ªæ¨¡æ€\",\n",
    "                    \"ç‰¹å¾æå–\": \"å¯¹åº”çš„ç¼–ç å™¨æå–æ¨¡æ€ç‰¹å¾\",\n",
    "                    \"ç‰¹å¾å¯¹é½\": \"æ—¶åºå¯¹é½å¼•æ“åŒæ­¥ä¸åŒæ¨¡æ€ç‰¹å¾\",\n",
    "                    \"å¤šæ¨¡æ€èåˆ\": \"èåˆå¯¹é½åçš„ç‰¹å¾ç”¨äºæ¨ç†\"\n",
    "                },\n",
    "                \"è¾“å‡ºæ•°æ®æµ\": {\n",
    "                    \"æ–‡æœ¬è¾“å‡º\": \"è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬å“åº”\",\n",
    "                    \"éŸ³é¢‘è¾“å‡º\": \"TTSåˆæˆçš„è¯­éŸ³å“åº”ï¼ˆå¯é€‰ï¼‰\",\n",
    "                    \"è§†è§‰è¾“å‡º\": \"ç”Ÿæˆçš„å›¾åƒæˆ–è§†é¢‘ï¼ˆå¯é€‰ï¼‰\",\n",
    "                    \"åé¦ˆæœºåˆ¶\": \"è¾“å‡ºç»“æœåé¦ˆåˆ°TDMè¿›è¡Œè´¨é‡è¯„ä¼°\"\n",
    "                }\n",
    "            },\n",
    "            \"æ€§èƒ½ä¼˜åŒ–é›†æˆ\": {\n",
    "                \"GPUèµ„æºç®¡ç†\": {\n",
    "                    \"æ˜¾å­˜åˆ†é…\": \"TDMåè°ƒä¸åŒæ¨¡å‹çš„æ˜¾å­˜ä½¿ç”¨\",\n",
    "                    \"è®¡ç®—è°ƒåº¦\": \"ä¼˜åŒ–GPU kernelçš„æ‰§è¡Œé¡ºåº\",\n",
    "                    \"æ‰¹å¤„ç†ä¼˜åŒ–\": \"åˆå¹¶ç›¸ä¼¼çš„è®¡ç®—ä»»åŠ¡\",\n",
    "                    \"æµæ°´çº¿å¹¶è¡Œ\": \"ä¸åŒæ¨¡æ€çš„å¤„ç†å¯ä»¥å¹¶è¡Œè¿›è¡Œ\"\n",
    "                },\n",
    "                \"CPUèµ„æºç®¡ç†\": {\n",
    "                    \"çº¿ç¨‹æ± \": \"TDMä½¿ç”¨ä¸“ç”¨çº¿ç¨‹æ± å¤„ç†ä¸åŒä»»åŠ¡\",\n",
    "                    \"NUMAä¼˜åŒ–\": \"è€ƒè™‘CPUå’Œå†…å­˜çš„æ‹“æ‰‘ç»“æ„\",\n",
    "                    \"ç¼“å­˜ä¼˜åŒ–\": \"ä¼˜åŒ–æ•°æ®è®¿é—®æ¨¡å¼æé«˜ç¼“å­˜å‘½ä¸­ç‡\",\n",
    "                    \"è´Ÿè½½å‡è¡¡\": \"åŠ¨æ€è°ƒæ•´ä¸åŒæ¨¡æ€çš„å¤„ç†è´Ÿè½½\"\n",
    "                },\n",
    "                \"å†…å­˜ä¼˜åŒ–\": {\n",
    "                    \"é›¶æ‹·è´\": \"å°½å¯èƒ½é¿å…æ•°æ®æ‹·è´æ“ä½œ\",\n",
    "                    \"å†…å­˜æ˜ å°„\": \"ä½¿ç”¨å†…å­˜æ˜ å°„æ–‡ä»¶å‡å°‘I/Oå¼€é”€\",\n",
    "                    \"å‹ç¼©å­˜å‚¨\": \"å¯¹å¤§æ•°æ®è¿›è¡Œå®æ—¶å‹ç¼©å­˜å‚¨\",\n",
    "                    \"åƒåœ¾å›æ”¶\": \"åŠæ—¶å›æ”¶ä¸å†ä½¿ç”¨çš„å†…å­˜\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def analyze_integration_architecture(self):\n",
    "        \"\"\"\n",
    "        åˆ†æTDMä¸MiniCPM-oçš„é›†æˆæ¶æ„\n",
    "        \"\"\"\n",
    "        print(\"ğŸ—ï¸ MiniCPM-oé›†æˆæ¶æ„åˆ†æ\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        for category, components in self.integration_architecture.items():\n",
    "            print(f\"\\nğŸ“š {category}:\")\n",
    "            \n",
    "            for component_name, details in components.items():\n",
    "                print(f\"\\n  ğŸ”§ {component_name}:\")\n",
    "                \n",
    "                for key, value in details.items():\n",
    "                    print(f\"    â€¢ {key}: {value}\")\n",
    "    \n",
    "    def visualize_integration_flow(self):\n",
    "        \"\"\"\n",
    "        å¯è§†åŒ–TDMåœ¨MiniCPM-oä¸­çš„é›†æˆæµç¨‹\n",
    "        \"\"\"\n",
    "        print(\"\\nğŸ”„ TDMé›†æˆæµç¨‹å¯è§†åŒ–\")\n",
    "        \n",
    "        # åˆ›å»ºæµç¨‹å›¾æ•°æ®\n",
    "        fig, ax = plt.subplots(figsize=(16, 10))\n",
    "        \n",
    "        # å®šä¹‰ç»„ä»¶ä½ç½®\n",
    "        components = {\n",
    "            'éŸ³é¢‘è¾“å…¥': (1, 8),\n",
    "            'è§†é¢‘è¾“å…¥': (1, 6),\n",
    "            'æ–‡æœ¬è¾“å…¥': (1, 4),\n",
    "            'TDMè°ƒåº¦å™¨': (4, 6),\n",
    "            'Whisperç¼–ç å™¨': (7, 8),\n",
    "            'EVA02ç¼–ç å™¨': (7, 6),\n",
    "            'æ–‡æœ¬ç¼–ç å™¨': (7, 4),\n",
    "            'æ—¶åºå¯¹é½': (10, 6),\n",
    "            'å¤šæ¨¡æ€èåˆ': (13, 6),\n",
    "            'Qwen2.5æ¨¡å‹': (16, 6),\n",
    "            'è¾“å‡ºç”Ÿæˆ': (19, 6)\n",
    "        }\n",
    "        \n",
    "        # ç»˜åˆ¶ç»„ä»¶\n",
    "        for name, (x, y) in components.items():\n",
    "            if 'TDM' in name:\n",
    "                color = 'lightcoral'\n",
    "            elif 'ç¼–ç å™¨' in name:\n",
    "                color = 'lightblue'\n",
    "            elif 'è¾“å…¥' in name:\n",
    "                color = 'lightgreen'\n",
    "            else:\n",
    "                color = 'lightyellow'\n",
    "            \n",
    "            # ç»˜åˆ¶çŸ©å½¢æ¡†\n",
    "            rect = plt.Rectangle((x-0.8, y-0.3), 1.6, 0.6, \n",
    "                               facecolor=color, edgecolor='black', linewidth=1)\n",
    "            ax.add_patch(rect)\n",
    "            \n",
    "            # æ·»åŠ æ–‡æœ¬\n",
    "            ax.text(x, y, name, ha='center', va='center', fontsize=8, weight='bold')\n",
    "        \n",
    "        # ç»˜åˆ¶è¿æ¥çº¿\n",
    "        connections = [\n",
    "            ('éŸ³é¢‘è¾“å…¥', 'TDMè°ƒåº¦å™¨'),\n",
    "            ('è§†é¢‘è¾“å…¥', 'TDMè°ƒåº¦å™¨'),\n",
    "            ('æ–‡æœ¬è¾“å…¥', 'TDMè°ƒåº¦å™¨'),\n",
    "            ('TDMè°ƒåº¦å™¨', 'Whisperç¼–ç å™¨'),\n",
    "            ('TDMè°ƒåº¦å™¨', 'EVA02ç¼–ç å™¨'),\n",
    "            ('TDMè°ƒåº¦å™¨', 'æ–‡æœ¬ç¼–ç å™¨'),\n",
    "            ('Whisperç¼–ç å™¨', 'æ—¶åºå¯¹é½'),\n",
    "            ('EVA02ç¼–ç å™¨', 'æ—¶åºå¯¹é½'),\n",
    "            ('æ–‡æœ¬ç¼–ç å™¨', 'æ—¶åºå¯¹é½'),\n",
    "            ('æ—¶åºå¯¹é½', 'å¤šæ¨¡æ€èåˆ'),\n",
    "            ('å¤šæ¨¡æ€èåˆ', 'Qwen2.5æ¨¡å‹'),\n",
    "            ('Qwen2.5æ¨¡å‹', 'è¾“å‡ºç”Ÿæˆ')\n",
    "        ]\n",
    "        \n",
    "        for start, end in connections:\n",
    "            start_pos = components[start]\n",
    "            end_pos = components[end]\n",
    "            \n",
    "            ax.annotate('', xy=end_pos, xytext=start_pos,\n",
    "                       arrowprops=dict(arrowstyle='->', lw=1.5, color='blue', alpha=0.7))\n",
    "        \n",
    "        ax.set_xlim(0, 21)\n",
    "        ax.set_ylim(3, 9)\n",
    "        ax.set_title('MiniCPM-oä¸­TDMé›†æˆæ¶æ„æµç¨‹å›¾', fontsize=14, weight='bold')\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # æ·»åŠ å›¾ä¾‹\n",
    "        legend_elements = [\n",
    "            plt.Rectangle((0, 0), 1, 1, facecolor='lightgreen', label='è¾“å…¥æ¨¡å—'),\n",
    "            plt.Rectangle((0, 0), 1, 1, facecolor='lightcoral', label='TDMæ ¸å¿ƒ'),\n",
    "            plt.Rectangle((0, 0), 1, 1, facecolor='lightblue', label='ç¼–ç å™¨'),\n",
    "            plt.Rectangle((0, 0), 1, 1, facecolor='lightyellow', label='å¤„ç†æ¨¡å—')\n",
    "        ]\n",
    "        ax.legend(handles=legend_elements, loc='upper right')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def demonstrate_real_world_scenario(self):\n",
    "        \"\"\"\n",
    "        æ¼”ç¤ºçœŸå®ä¸–ç•Œåº”ç”¨åœºæ™¯\n",
    "        \"\"\"\n",
    "        print(\"\\nğŸŒ çœŸå®ä¸–ç•Œåº”ç”¨åœºæ™¯æ¼”ç¤º\")\n",
    "        print(\"=\"*35)\n",
    "        \n",
    "        scenarios = {\n",
    "            \"æ™ºèƒ½å®¢æœå¯¹è¯\": {\n",
    "                \"åœºæ™¯æè¿°\": \"ç”¨æˆ·é€šè¿‡è¯­éŸ³å’Œå±å¹•å…±äº«ä¸AIå®¢æœäº¤äº’\",\n",
    "                \"è¾“å…¥æ¨¡æ€\": [\"ç”¨æˆ·è¯­éŸ³\", \"å±å¹•æˆªå›¾\", \"æ–‡å­—æ¶ˆæ¯\"],\n",
    "                \"TDMä½œç”¨\": \"åŒæ­¥å¤„ç†è¯­éŸ³è¯†åˆ«ã€å›¾åƒç†è§£å’Œæ–‡æœ¬åˆ†æ\",\n",
    "                \"è¾“å‡ºç»“æœ\": \"ç»¼åˆç†è§£ç”¨æˆ·é—®é¢˜ï¼Œæä¾›å‡†ç¡®çš„è¯­éŸ³å’Œæ–‡å­—å›å¤\",\n",
    "                \"æ€§èƒ½è¦æ±‚\": \"<2ç§’å“åº”æ—¶é—´ï¼Œ>95%å‡†ç¡®ç‡\"\n",
    "            },\n",
    "            \"å®æ—¶è§†é¢‘ä¼šè®®åŠ©æ‰‹\": {\n",
    "                \"åœºæ™¯æè¿°\": \"AIåŠ©æ‰‹å®æ—¶ç†è§£ä¼šè®®å†…å®¹å¹¶æä¾›æ™ºèƒ½æ‘˜è¦\",\n",
    "                \"è¾“å…¥æ¨¡æ€\": [\"å¤šäººè¯­éŸ³\", \"å±å¹•å…±äº«\", \"èŠå¤©æ¶ˆæ¯\"],\n",
    "                \"TDMä½œç”¨\": \"å®æ—¶åŒæ­¥å¤„ç†éŸ³è§†é¢‘æµå’Œæ–‡æœ¬æ¶ˆæ¯\",\n",
    "                \"è¾“å‡ºç»“æœ\": \"å®æ—¶å­—å¹•ã€ä¼šè®®æ‘˜è¦ã€æ™ºèƒ½æé†’\",\n",
    "                \"æ€§èƒ½è¦æ±‚\": \"<500mså»¶è¿Ÿï¼Œæ”¯æŒ4Kè§†é¢‘\"\n",
    "            },\n",
    "            \"å¤šæ¨¡æ€å†…å®¹åˆ›ä½œ\": {\n",
    "                \"åœºæ™¯æè¿°\": \"ç”¨æˆ·é€šè¿‡è¯­éŸ³æè¿°å’Œå›¾ç‰‡å‚è€ƒåˆ›ä½œè§†é¢‘å†…å®¹\",\n",
    "                \"è¾“å…¥æ¨¡æ€\": [\"è¯­éŸ³æŒ‡ä»¤\", \"å‚è€ƒå›¾ç‰‡\", \"æ–‡å­—è„šæœ¬\"],\n",
    "                \"TDMä½œç”¨\": \"åè°ƒç†è§£åˆ›ä½œæ„å›¾ï¼Œç”Ÿæˆå¤šæ¨¡æ€å†…å®¹\",\n",
    "                \"è¾“å‡ºç»“æœ\": \"è‡ªåŠ¨ç”Ÿæˆè§†é¢‘è„šæœ¬ã€é…éŸ³å’Œè§†è§‰æ•ˆæœ\",\n",
    "                \"æ€§èƒ½è¦æ±‚\": \"<10ç§’ç”Ÿæˆæ—¶é—´ï¼Œé«˜è´¨é‡è¾“å‡º\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        for scenario_name, details in scenarios.items():\n",
    "            print(f\"\\nğŸ¯ {scenario_name}:\")\n",
    "            for key, value in details.items():\n",
    "                if isinstance(value, list):\n",
    "                    print(f\"  â€¢ {key}: {', '.join(value)}\")\n",
    "                else:\n",
    "                    print(f\"  â€¢ {key}: {value}\")\n",
    "\n",
    "# æ‰§è¡Œé›†æˆåˆ†æ\n",
    "integration_analysis = MiniCPMIntegrationAnalysis()\n",
    "integration_analysis.analyze_integration_architecture()\n",
    "integration_analysis.visualize_integration_flow()\n",
    "integration_analysis.demonstrate_real_world_scenario()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. æ€»ç»“ä¸å±•æœ›\n",
    "\n",
    "### 6.1 TDMæŠ€æœ¯æ€»ç»“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ¯ MiniCPM-oæ—¶åˆ†å¤ç”¨(TDM)æœºåˆ¶æ·±åº¦åˆ†ææ€»ç»“\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "summary = {\n",
    "    \"æ ¸å¿ƒæŠ€æœ¯æˆå°±\": {\n",
    "        \"æ—¶åºåŒæ­¥ç²¾åº¦\": \"å®ç°äº†Â±20msçš„å¤šæ¨¡æ€æ•°æ®æ—¶åºå¯¹é½\",\n",
    "        \"å®æ—¶å¤„ç†èƒ½åŠ›\": \"æ”¯æŒ100HzéŸ³é¢‘ã€60fpsè§†é¢‘çš„å®æ—¶å¤„ç†\",\n",
    "        \"å†…å­˜æ•ˆç‡\": \"é€šè¿‡å‹ç¼©å’Œç¼“å­˜ä¼˜åŒ–ï¼Œå†…å­˜ä½¿ç”¨æ•ˆç‡æå‡60%\",\n",
    "        \"å¹¶å‘æ€§èƒ½\": \"å¤šçº¿ç¨‹å¤„ç†ååé‡æ¯”ä¼ ç»Ÿæ–¹æ³•æå‡2-3å€\",\n",
    "        \"å»¶è¿Ÿæ§åˆ¶\": \"ç«¯åˆ°ç«¯å»¶è¿Ÿæ§åˆ¶åœ¨500msä»¥å†…\"\n",
    "    },\n",
    "    \"æŠ€æœ¯åˆ›æ–°ç‚¹\": {\n",
    "        \"è‡ªé€‚åº”æ—¶é—´ç‰‡è°ƒåº¦\": \"æ ¹æ®æ¨¡æ€ä¼˜å…ˆçº§å’Œç³»ç»Ÿè´Ÿè½½åŠ¨æ€è°ƒæ•´æ—¶é—´ç‰‡\",\n",
    "        \"é¢„æµ‹æ€§ç¼“å†²ç®¡ç†\": \"åŸºäºå†å²æ¨¡å¼é¢„æµ‹æ•°æ®éœ€æ±‚ï¼Œæå‰å‡†å¤‡èµ„æº\",\n",
    "        \"å¤šå±‚æ¬¡æ—¶åºå¯¹é½\": \"ä»ç²—ç²’åº¦åˆ°ç»†ç²’åº¦çš„åˆ†å±‚å¯¹é½ç­–ç•¥\",\n",
    "        \"æ™ºèƒ½æµæ§æœºåˆ¶\": \"è‡ªåŠ¨æ£€æµ‹å’Œå¤„ç†æ•°æ®æµå¼‚å¸¸æƒ…å†µ\",\n",
    "        \"æ— é”å¹¶å‘è®¾è®¡\": \"ä½¿ç”¨åŸå­æ“ä½œå’Œæ— é”æ•°æ®ç»“æ„æå‡å¹¶å‘æ€§èƒ½\"\n",
    "    },\n",
    "    \"å®é™…åº”ç”¨ä»·å€¼\": {\n",
    "        \"å®æ—¶å¯¹è¯ç³»ç»Ÿ\": \"æ”¯æŒè‡ªç„¶æµç•…çš„å¤šæ¨¡æ€äººæœºå¯¹è¯\",\n",
    "        \"æ™ºèƒ½ä¼šè®®åŠ©æ‰‹\": \"å®æ—¶ç†è§£å’Œå¤„ç†ä¼šè®®ä¸­çš„å¤šæ¨¡æ€ä¿¡æ¯\",\n",
    "        \"å†…å®¹åˆ›ä½œå·¥å…·\": \"ååŠ©ç”¨æˆ·è¿›è¡Œå¤šæ¨¡æ€å†…å®¹çš„æ™ºèƒ½åˆ›ä½œ\",\n",
    "        \"æ•™è‚²åŸ¹è®­å¹³å°\": \"æä¾›æ²‰æµ¸å¼çš„å¤šæ¨¡æ€å­¦ä¹ ä½“éªŒ\",\n",
    "        \"åŒ»ç–—è¯Šæ–­è¾…åŠ©\": \"ç»¼åˆåˆ†æåŒ»å­¦å½±åƒã€è¯­éŸ³å’Œæ–‡æœ¬ä¿¡æ¯\"\n",
    "    },\n",
    "    \"æŠ€æœ¯æŒ‘æˆ˜ä¸è§£å†³æ–¹æ¡ˆ\": {\n",
    "        \"æ—¶åºåŒæ­¥å¤æ‚æ€§\": \"é€šè¿‡å‚è€ƒæ—¶é—´çº¿å’Œæ’å€¼ç®—æ³•è§£å†³\",\n",
    "        \"èµ„æºç«äº‰é—®é¢˜\": \"ä½¿ç”¨ä¼˜å…ˆçº§è°ƒåº¦å’Œèµ„æºæ± ç®¡ç†\",\n",
    "        \"å®æ—¶æ€§è¦æ±‚\": \"é‡‡ç”¨é¢„æµ‹æ€§è°ƒåº¦å’Œç¼“å­˜é¢„çƒ­ç­–ç•¥\",\n",
    "        \"æ‰©å±•æ€§éœ€æ±‚\": \"è®¾è®¡æ¨¡å—åŒ–æ¶æ„æ”¯æŒæ–°æ¨¡æ€çš„å¿«é€Ÿé›†æˆ\",\n",
    "        \"é”™è¯¯æ¢å¤æœºåˆ¶\": \"å®ç°å¤šå±‚æ¬¡çš„é”™è¯¯æ£€æµ‹å’Œè‡ªåŠ¨æ¢å¤\"\n",
    "    },\n",
    "    \"æœªæ¥å‘å±•æ–¹å‘\": {\n",
    "        \"AIé©±åŠ¨çš„è°ƒåº¦ä¼˜åŒ–\": \"ä½¿ç”¨æœºå™¨å­¦ä¹ ä¼˜åŒ–æ—¶é—´ç‰‡åˆ†é…ç­–ç•¥\",\n",
    "        \"è¾¹ç¼˜è®¡ç®—é€‚é…\": \"é’ˆå¯¹è¾¹ç¼˜è®¾å¤‡çš„è½»é‡åŒ–TDMå®ç°\",\n",
    "        \"äº‘ç«¯ååŒå¤„ç†\": \"äº‘è¾¹ååŒçš„åˆ†å¸ƒå¼TDMæ¶æ„\",\n",
    "        \"æ–°æ¨¡æ€æ”¯æŒ\": \"æ‰©å±•æ”¯æŒè§¦è§‰ã€å—…è§‰ç­‰æ–°å…´æ¨¡æ€\",\n",
    "        \"æ ‡å‡†åŒ–æ¨è¿›\": \"æ¨åŠ¨TDMæŠ€æœ¯çš„è¡Œä¸šæ ‡å‡†åŒ–\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for category, achievements in summary.items():\n",
    "    print(f\"\\nğŸš€ {category}:\")\n",
    "    for key, value in achievements.items():\n",
    "        print(f\"  â€¢ {key}: {value}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ å…³é”®æ´å¯Ÿ:\")\n",
    "insights = [\n",
    "    \"TDMä¸ä»…æ˜¯æŠ€æœ¯å®ç°ï¼Œæ›´æ˜¯å¤šæ¨¡æ€AIç³»ç»Ÿè®¾è®¡çš„æ–°èŒƒå¼\",\n",
    "    \"æ—¶åºåŒæ­¥æ˜¯å®ç°çœŸæ­£æ™ºèƒ½å¤šæ¨¡æ€äº¤äº’çš„å…³é”®æŠ€æœ¯\",\n",
    "    \"ç³»ç»Ÿæ€§çš„ä¼˜åŒ–ç­–ç•¥æ¯”å•ç‚¹ä¼˜åŒ–æ›´èƒ½æå‡æ•´ä½“æ€§èƒ½\",\n",
    "    \"å®æ—¶æ€§å’Œå‡†ç¡®æ€§çš„å¹³è¡¡éœ€è¦ç²¾å¿ƒçš„å·¥ç¨‹è®¾è®¡\",\n",
    "    \"æ¨¡å—åŒ–å’Œå¯æ‰©å±•çš„æ¶æ„æ˜¯åº”å¯¹æœªæ¥éœ€æ±‚çš„åŸºç¡€\"\n",
    "]\n",
    "\n",
    "for i, insight in enumerate(insights, 1):\n",
    "    print(f\"  {i}. {insight}\")\n",
    "\n",
    "print(\"\\nğŸ‰ åˆ†æå®Œæˆï¼\")\n",
    "print(\"MiniCPM-oçš„TDMæœºåˆ¶ä¸ºå¤šæ¨¡æ€AIçš„å®æ—¶äº¤äº’æä¾›äº†å¼ºå¤§çš„æŠ€æœ¯åŸºç¡€ï¼Œ\")\n",
    "print(\"å…¶åˆ›æ–°çš„è®¾è®¡ç†å¿µå’Œä¼˜åŒ–ç­–ç•¥ä¸ºæ•´ä¸ªè¡Œä¸šæ ‘ç«‹äº†æ–°çš„æ ‡æ†ã€‚\")\n",
    "print(\"éšç€æŠ€æœ¯çš„ä¸æ–­å‘å±•ï¼ŒTDMå°†åœ¨æ›´å¤šåœºæ™¯ä¸­å‘æŒ¥é‡è¦ä½œç”¨ï¼Œ\")\n",
    "print(\"æ¨åŠ¨äººå·¥æ™ºèƒ½å‘æ›´åŠ è‡ªç„¶ã€æ™ºèƒ½çš„æ–¹å‘å‘å±•ã€‚\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
